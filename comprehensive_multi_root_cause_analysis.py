#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åŒ…æ‹¬çš„å¤šé‡æ ¹æœ¬åŸå› åˆ†æã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆã‚¦ãƒ«ãƒˆãƒ©ã‚·ãƒ³ã‚¯ãƒ»çµ¶å¯¾ã«å˜˜ã‚’ã¤ã‹ãªã„ï¼‰
2025å¹´å°‚é–€å®¶ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã«åŸºã¥ãè¤‡åˆå•é¡Œã®å¾¹åº•èª¿æŸ»

2é€±é–“æ²»ã‚‰ãªã„å•é¡Œã¯å˜ä¸€åŸå› ã§ã¯ãªã„
- è¤‡æ•°ã®æ ¹æœ¬åŸå› ã‚’åŒæ™‚èª¿æŸ»
- ã‚·ã‚¹ãƒ†ãƒ ç›¸äº’ä½œç”¨ã®åˆ†æ
- ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼å…¨ä½“ã®æ¤œè¨¼
- ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãƒ¬ãƒ™ãƒ«ã®å•é¡Œèª¿æŸ»
"""

import sys
import os
import csv
import json
import re
import logging
from datetime import datetime
from collections import defaultdict, Counter
import importlib.util

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def comprehensive_multi_root_cause_analysis():
    """
    è¤‡åˆå•é¡Œã®åŒ…æ‹¬çš„æ ¹æœ¬åŸå› åˆ†æï¼ˆ2025å¹´å°‚é–€å®¶æ‰‹æ³•ï¼‰
    - ãƒ‡ãƒ¼ã‚¿ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®å•é¡Œ
    - ãƒ­ã‚¸ãƒƒã‚¯ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®å•é¡Œ  
    - ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãƒ¬ãƒ™ãƒ«ã®å•é¡Œ
    - ã‚·ã‚¹ãƒ†ãƒ ç›¸äº’ä½œç”¨ã®å•é¡Œ
    """
    
    print("=" * 100)
    print("åŒ…æ‹¬çš„å¤šé‡æ ¹æœ¬åŸå› åˆ†æï¼ˆã‚¦ãƒ«ãƒˆãƒ©ã‚·ãƒ³ã‚¯ãƒ»çµ¶å¯¾ã«å˜˜ã‚’ã¤ã‹ãªã„ï¼‰")
    print("2é€±é–“æ²»ã‚‰ãªã„å•é¡Œã®è¤‡åˆçš„æ ¹æœ¬åŸå› ã‚’å¾¹åº•èª¿æŸ»")
    print("=" * 100)
    
    analysis_results = {
        'timestamp': datetime.now().isoformat(),
        'analysis_scope': 'comprehensive_multi_root_cause',
        'root_causes': [],
        'system_interactions': [],
        'data_layer_issues': [],
        'logic_layer_issues': [],
        'architecture_issues': [],
        'configuration_issues': [],
        'runtime_issues': []
    }
    
    print("\nğŸ” ROOT CAUSE 1: ãƒ‡ãƒ¼ã‚¿ãƒ¬ã‚¤ãƒ¤ãƒ¼æ§‹é€ çš„å•é¡Œã®èª¿æŸ»")
    data_issues = analyze_data_layer_structure()
    analysis_results['data_layer_issues'] = data_issues
    
    print("\nğŸ” ROOT CAUSE 2: ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ­ã‚¸ãƒƒã‚¯å•é¡Œã®èª¿æŸ»")
    logic_issues = analyze_application_logic()
    analysis_results['logic_layer_issues'] = logic_issues
    
    print("\nğŸ” ROOT CAUSE 3: ã‚·ã‚¹ãƒ†ãƒ è¨­å®šãƒ»ç’°å¢ƒå•é¡Œã®èª¿æŸ»")
    config_issues = analyze_system_configuration()
    analysis_results['configuration_issues'] = config_issues
    
    print("\nğŸ” ROOT CAUSE 4: ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼ãƒ»ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å•é¡Œã®èª¿æŸ»")
    pipeline_issues = analyze_data_pipeline()
    analysis_results['runtime_issues'] = pipeline_issues
    
    print("\nğŸ” ROOT CAUSE 5: ç›¸äº’ä½œç”¨ãƒ»ä¾å­˜é–¢ä¿‚å•é¡Œã®èª¿æŸ»")
    interaction_issues = analyze_system_interactions()
    analysis_results['system_interactions'] = interaction_issues
    
    print("\nğŸ” ROOT CAUSE 6: ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è¨­è¨ˆå•é¡Œã®èª¿æŸ»")
    architecture_issues = analyze_architecture_design()
    analysis_results['architecture_issues'] = architecture_issues
    
    # ç·åˆåˆ†æã¨å„ªå…ˆåº¦ä»˜ã‘
    final_analysis = synthesize_root_causes(analysis_results)
    
    # çµæœä¿å­˜
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    result_file = f"comprehensive_multi_root_cause_analysis_{timestamp}.json"
    
    with open(result_file, 'w', encoding='utf-8') as f:
        json.dump(analysis_results, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ“Š åŒ…æ‹¬çš„åˆ†æçµæœä¿å­˜: {result_file}")
    return analysis_results

def analyze_data_layer_structure():
    """ãƒ‡ãƒ¼ã‚¿ãƒ¬ã‚¤ãƒ¤ãƒ¼æ§‹é€ çš„å•é¡Œã®è©³ç´°åˆ†æ"""
    print("ãƒ‡ãƒ¼ã‚¿ãƒ¬ã‚¤ãƒ¤ãƒ¼æ§‹é€ åˆ†æé–‹å§‹...")
    
    data_issues = []
    
    # 1. CSVãƒ•ã‚¡ã‚¤ãƒ«æ§‹é€ ã®ä¸€è²«æ€§ãƒã‚§ãƒƒã‚¯
    print("  1. CSVãƒ•ã‚¡ã‚¤ãƒ«æ§‹é€ ä¸€è²«æ€§ãƒã‚§ãƒƒã‚¯")
    csv_consistency_issues = check_csv_structure_consistency()
    if csv_consistency_issues:
        data_issues.extend(csv_consistency_issues)
    
    # 2. ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å•é¡Œãƒã‚§ãƒƒã‚¯
    print("  2. ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å•é¡Œãƒã‚§ãƒƒã‚¯")
    encoding_issues = check_encoding_issues()
    if encoding_issues:
        data_issues.extend(encoding_issues)
    
    # 3. ãƒ‡ãƒ¼ã‚¿å‹ä¸æ•´åˆãƒã‚§ãƒƒã‚¯
    print("  3. ãƒ‡ãƒ¼ã‚¿å‹ä¸æ•´åˆãƒã‚§ãƒƒã‚¯")
    datatype_issues = check_datatype_inconsistencies()
    if datatype_issues:
        data_issues.extend(datatype_issues)
    
    # 4. é‡è¤‡ãƒ‡ãƒ¼ã‚¿ãƒ»ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯
    print("  4. é‡è¤‡ãƒ‡ãƒ¼ã‚¿ãƒ»å“è³ªãƒã‚§ãƒƒã‚¯")
    quality_issues = check_data_quality()
    if quality_issues:
        data_issues.extend(quality_issues)
    
    return data_issues

def check_csv_structure_consistency():
    """CSVãƒ•ã‚¡ã‚¤ãƒ«æ§‹é€ ã®ä¸€è²«æ€§ãƒã‚§ãƒƒã‚¯"""
    issues = []
    
    VALID_YEARS = [2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019]
    expected_headers = ['id', 'category', 'question', 'option_a', 'option_b', 'option_c', 'option_d', 'correct_answer']
    
    for year in VALID_YEARS:
        csv_path = f'rccm-quiz-app/data/4-2_{year}.csv'
        if not os.path.exists(csv_path):
            continue
        
        try:
            with open(csv_path, 'r', encoding='utf-8') as f:
                reader = csv.DictReader(f)
                headers = reader.fieldnames
                
                # ãƒ˜ãƒƒãƒ€ãƒ¼ä¸æ•´åˆãƒã‚§ãƒƒã‚¯
                missing_headers = set(expected_headers) - set(headers or [])
                extra_headers = set(headers or []) - set(expected_headers)
                
                if missing_headers:
                    issues.append({
                        'type': 'missing_headers',
                        'year': year,
                        'missing': list(missing_headers),
                        'severity': 'high'
                    })
                
                if extra_headers:
                    issues.append({
                        'type': 'extra_headers',
                        'year': year,
                        'extra': list(extra_headers),
                        'severity': 'medium'
                    })
                
                # ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°ã®å¹´åº¦é–“æ¯”è¼ƒ
                row_count = sum(1 for row in reader)
                if row_count < 200:  # ç•°å¸¸ã«å°‘ãªã„
                    issues.append({
                        'type': 'insufficient_records',
                        'year': year,
                        'count': row_count,
                        'severity': 'high'
                    })
                elif row_count > 500:  # ç•°å¸¸ã«å¤šã„
                    issues.append({
                        'type': 'excessive_records',
                        'year': year,
                        'count': row_count,
                        'severity': 'medium'
                    })
                    
        except Exception as e:
            issues.append({
                'type': 'file_access_error',
                'year': year,
                'error': str(e),
                'severity': 'critical'
            })
    
    return issues

def check_encoding_issues():
    """ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å•é¡Œã®è©³ç´°ãƒã‚§ãƒƒã‚¯"""
    issues = []
    
    VALID_YEARS = [2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019]
    
    for year in VALID_YEARS:
        csv_path = f'rccm-quiz-app/data/4-2_{year}.csv'
        if not os.path.exists(csv_path):
            continue
        
        # UTF-8ã§ã®ã‚¢ã‚¯ã‚»ã‚¹ãƒ†ã‚¹ãƒˆ
        utf8_success = False
        try:
            with open(csv_path, 'r', encoding='utf-8') as f:
                sample = f.read(1000)
                utf8_success = True
        except UnicodeDecodeError:
            pass
        
        # Shift_JISã§ã®ã‚¢ã‚¯ã‚»ã‚¹ãƒ†ã‚¹ãƒˆ
        sjis_success = False
        try:
            with open(csv_path, 'r', encoding='shift_jis') as f:
                sample = f.read(1000)
                sjis_success = True
        except UnicodeDecodeError:
            pass
        
        if not utf8_success and not sjis_success:
            issues.append({
                'type': 'encoding_error',
                'year': year,
                'description': 'UTF-8ã¨Shift_JISä¸¡æ–¹ã§ã‚¢ã‚¯ã‚»ã‚¹å¤±æ•—',
                'severity': 'critical'
            })
        elif not utf8_success and sjis_success:
            issues.append({
                'type': 'encoding_inconsistency',
                'year': year,
                'description': 'Shift_JISã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ï¼ˆUTF-8çµ±ä¸€ãŒæ¨å¥¨ï¼‰',
                'severity': 'medium'
            })
    
    return issues

def check_datatype_inconsistencies():
    """ãƒ‡ãƒ¼ã‚¿å‹ä¸æ•´åˆã®è©³ç´°ãƒã‚§ãƒƒã‚¯"""
    issues = []
    
    VALID_YEARS = [2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019]
    
    for year in VALID_YEARS:
        csv_path = f'rccm-quiz-app/data/4-2_{year}.csv'
        if not os.path.exists(csv_path):
            continue
        
        try:
            with open(csv_path, 'r', encoding='utf-8') as f:
                reader = csv.DictReader(f)
                
                for row_num, row in enumerate(reader, 1):
                    # IDå‹ãƒã‚§ãƒƒã‚¯
                    try:
                        int(row.get('id', ''))
                    except (ValueError, TypeError):
                        issues.append({
                            'type': 'invalid_id_format',
                            'year': year,
                            'row': row_num,
                            'value': row.get('id'),
                            'severity': 'high'
                        })
                    
                    # correct_answerå½¢å¼ãƒã‚§ãƒƒã‚¯
                    correct_answer = row.get('correct_answer', '').strip()
                    if correct_answer not in ['1', '2', '3', '4', 'A', 'B', 'C', 'D', 'a', 'b', 'c', 'd']:
                        if correct_answer:  # ç©ºã§ãªã„å ´åˆã®ã¿
                            issues.append({
                                'type': 'invalid_answer_format',
                                'year': year,
                                'row': row_num,
                                'value': correct_answer,
                                'severity': 'high'
                            })
                    
                    # å•é¡Œæ–‡é•·ã™ãã‚‹ãƒã‚§ãƒƒã‚¯
                    question_text = row.get('question', '')
                    if len(question_text) > 2000:  # ç•°å¸¸ã«é•·ã„
                        issues.append({
                            'type': 'excessive_question_length',
                            'year': year,
                            'row': row_num,
                            'length': len(question_text),
                            'severity': 'medium'
                        })
                    elif len(question_text) < 10:  # ç•°å¸¸ã«çŸ­ã„
                        issues.append({
                            'type': 'insufficient_question_length',
                            'year': year,
                            'row': row_num,
                            'length': len(question_text),
                            'severity': 'high'
                        })
                    
        except Exception as e:
            issues.append({
                'type': 'datatype_check_error',
                'year': year,
                'error': str(e),
                'severity': 'medium'
            })
    
    return issues

def check_data_quality():
    """ãƒ‡ãƒ¼ã‚¿å“è³ªå•é¡Œã®è©³ç´°ãƒã‚§ãƒƒã‚¯"""
    issues = []
    
    # é‡è¤‡IDãƒã‚§ãƒƒã‚¯
    all_ids = set()
    duplicate_ids = set()
    
    VALID_YEARS = [2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019]
    
    for year in VALID_YEARS:
        csv_path = f'rccm-quiz-app/data/4-2_{year}.csv'
        if not os.path.exists(csv_path):
            continue
        
        try:
            with open(csv_path, 'r', encoding='utf-8') as f:
                reader = csv.DictReader(f)
                
                year_ids = set()
                for row in reader:
                    qid = row.get('id')
                    if qid:
                        if qid in all_ids:
                            duplicate_ids.add(qid)
                        if qid in year_ids:
                            issues.append({
                                'type': 'duplicate_id_within_year',
                                'year': year,
                                'id': qid,
                                'severity': 'high'
                            })
                        all_ids.add(qid)
                        year_ids.add(qid)
                        
        except Exception as e:
            issues.append({
                'type': 'quality_check_error',
                'year': year,
                'error': str(e),
                'severity': 'medium'
            })
    
    if duplicate_ids:
        issues.append({
            'type': 'duplicate_ids_across_years',
            'ids': list(duplicate_ids),
            'count': len(duplicate_ids),
            'severity': 'critical'
        })
    
    return issues

def analyze_application_logic():
    """ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ­ã‚¸ãƒƒã‚¯å•é¡Œã®è©³ç´°åˆ†æ"""
    print("ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ­ã‚¸ãƒƒã‚¯åˆ†æé–‹å§‹...")
    
    logic_issues = []
    
    # app.pyã®åˆ†æ
    app_py_path = "rccm-quiz-app/app.py"
    if os.path.exists(app_py_path):
        # 1. é–¢æ•°ã®è¤‡é›‘æ€§ãƒã‚§ãƒƒã‚¯
        print("  1. é–¢æ•°è¤‡é›‘æ€§ãƒã‚§ãƒƒã‚¯")
        complexity_issues = check_function_complexity(app_py_path)
        logic_issues.extend(complexity_issues)
        
        # 2. ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒã‚§ãƒƒã‚¯
        print("  2. ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒã‚§ãƒƒã‚¯")
        error_handling_issues = check_error_handling(app_py_path)
        logic_issues.extend(error_handling_issues)
        
        # 3. ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†ãƒ­ã‚¸ãƒƒã‚¯ãƒã‚§ãƒƒã‚¯
        print("  3. ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†ãƒ­ã‚¸ãƒƒã‚¯ãƒã‚§ãƒƒã‚¯")
        session_issues = check_session_logic(app_py_path)
        logic_issues.extend(session_issues)
        
        # 4. ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ãƒ­ã‚¸ãƒƒã‚¯ãƒã‚§ãƒƒã‚¯
        print("  4. ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ãƒ­ã‚¸ãƒƒã‚¯ãƒã‚§ãƒƒã‚¯")
        filtering_issues = check_filtering_logic(app_py_path)
        logic_issues.extend(filtering_issues)
    
    return logic_issues

def check_function_complexity(file_path):
    """é–¢æ•°ã®è¤‡é›‘æ€§å•é¡Œãƒã‚§ãƒƒã‚¯"""
    issues = []
    
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # get_department_questionsé–¢é€£ã®é–¢æ•°ã‚’æ¤œç´¢
        dept_functions = re.findall(r'def (get_department_questions.*?)\(.*?\):', content)
        
        for func_name in dept_functions:
            # é–¢æ•°ã®é–‹å§‹ä½ç½®ã‚’ç‰¹å®š
            func_start = content.find(f'def {func_name}(')
            if func_start == -1:
                continue
            
            # é–¢æ•°ã®ãŠãŠã‚ˆãã®çµ‚äº†ä½ç½®ã‚’ç‰¹å®šï¼ˆæ¬¡ã®defæ–‡ã¾ã§ï¼‰
            func_content = content[func_start:]
            next_def = func_content.find('\ndef ', 1)
            if next_def != -1:
                func_content = func_content[:next_def]
            
            # è¤‡é›‘æ€§æŒ‡æ¨™ã®è¨ˆç®—
            line_count = len(func_content.split('\n'))
            if_count = len(re.findall(r'\bif\b', func_content))
            for_count = len(re.findall(r'\bfor\b', func_content))
            try_count = len(re.findall(r'\btry\b', func_content))
            
            complexity_score = if_count + for_count * 2 + try_count
            
            if line_count > 200:
                issues.append({
                    'type': 'excessive_function_length',
                    'function': func_name,
                    'lines': line_count,
                    'severity': 'high'
                })
            
            if complexity_score > 20:
                issues.append({
                    'type': 'high_cyclomatic_complexity',
                    'function': func_name,
                    'complexity': complexity_score,
                    'severity': 'high'
                })
    
    except Exception as e:
        issues.append({
            'type': 'complexity_analysis_error',
            'error': str(e),
            'severity': 'medium'
        })
    
    return issues

def check_error_handling(file_path):
    """ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å•é¡Œãƒã‚§ãƒƒã‚¯"""
    issues = []
    
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # try-exceptæ–‡ã®åˆ†æ
        try_blocks = re.findall(r'try:(.*?)except', content, re.DOTALL)
        
        for i, try_block in enumerate(try_blocks):
            # ç©ºã®exceptãƒ–ãƒ­ãƒƒã‚¯ãƒã‚§ãƒƒã‚¯
            if re.search(r'except.*?:\s*pass', content):
                issues.append({
                    'type': 'empty_except_block',
                    'location': f'try_block_{i}',
                    'severity': 'high'
                })
            
            # æ±ç”¨exception catchingãƒã‚§ãƒƒã‚¯
            if re.search(r'except\s*:', content) or re.search(r'except Exception:', content):
                issues.append({
                    'type': 'generic_exception_catching',
                    'location': f'try_block_{i}',
                    'severity': 'medium'
                })
        
        # ãƒªã‚½ãƒ¼ã‚¹ç®¡ç†ãƒã‚§ãƒƒã‚¯ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«æ“ä½œãªã©ï¼‰
        file_opens = re.findall(r'open\s*\(', content)
        with_statements = re.findall(r'with\s+open', content)
        
        if len(file_opens) > len(with_statements):
            issues.append({
                'type': 'improper_resource_management',
                'opens': len(file_opens),
                'with_statements': len(with_statements),
                'severity': 'medium'
            })
    
    except Exception as e:
        issues.append({
            'type': 'error_handling_analysis_error',
            'error': str(e),
            'severity': 'medium'
        })
    
    return issues

def check_session_logic(file_path):
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†ãƒ­ã‚¸ãƒƒã‚¯å•é¡Œãƒã‚§ãƒƒã‚¯"""
    issues = []
    
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³é–¢é€£ã®å¤‰æ•°ã‚¢ã‚¯ã‚»ã‚¹ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒã‚§ãƒƒã‚¯
        session_gets = len(re.findall(r'session\.get\(', content))
        session_sets = len(re.findall(r'session\[.*?\]\s*=', content))
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¢ã‚¯ã‚»ã‚¹ãŒå¤šã™ãã‚‹å ´åˆ
        if session_gets > 100:
            issues.append({
                'type': 'excessive_session_access',
                'get_count': session_gets,
                'set_count': session_sets,
                'severity': 'medium'
            })
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚­ãƒ¼ã®ä¸€è²«æ€§ãƒã‚§ãƒƒã‚¯
        session_keys = re.findall(r'session\.get\([\'\"](.*?)[\'\"]', content)
        session_keys.extend(re.findall(r'session\[[\'\"](.*?)[\'\"]', content))
        
        key_variations = defaultdict(list)
        for key in session_keys:
            base_key = re.sub(r'[_-]', '', key.lower())
            key_variations[base_key].append(key)
        
        for base_key, variations in key_variations.items():
            if len(variations) > 1:
                issues.append({
                    'type': 'inconsistent_session_keys',
                    'base_key': base_key,
                    'variations': variations,
                    'severity': 'medium'
                })
    
    except Exception as e:
        issues.append({
            'type': 'session_logic_analysis_error',
            'error': str(e),
            'severity': 'medium'
        })
    
    return issues

def check_filtering_logic(file_path):
    """ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ãƒ­ã‚¸ãƒƒã‚¯å•é¡Œãƒã‚§ãƒƒã‚¯"""
    issues = []
    
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # ã‚«ãƒ†ã‚´ãƒªãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã®è¤‡æ•°ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒã‚§ãƒƒã‚¯
        category_filters = re.findall(r'row\.get\([\'\"]\w*category\w*[\'\"]\)', content)
        if len(set(category_filters)) > 1:
            issues.append({
                'type': 'inconsistent_category_access',
                'patterns': list(set(category_filters)),
                'severity': 'high'
            })
        
        # æ–‡å­—åˆ—æ¯”è¼ƒã®æ–¹æ³•ãƒã‚§ãƒƒã‚¯
        string_comparisons = re.findall(r'==\s*[\'\"](.*?)[\'\"]', content)
        strip_usage = len(re.findall(r'\.strip\(\)', content))
        
        if len(string_comparisons) > 50 and strip_usage < 10:
            issues.append({
                'type': 'insufficient_string_normalization',
                'comparisons': len(string_comparisons),
                'strip_usage': strip_usage,
                'severity': 'medium'
            })
        
        # ãƒ«ãƒ¼ãƒ—å†…ã§ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ã‚¯ã‚»ã‚¹ãƒã‚§ãƒƒã‚¯
        for_loops = re.findall(r'for\s+.*?:', content)
        if len(for_loops) > 5:
            # ãƒ«ãƒ¼ãƒ—å†…ã§ã®open()ãƒã‚§ãƒƒã‚¯
            issues.append({
                'type': 'potential_inefficient_loops',
                'loop_count': len(for_loops),
                'severity': 'medium'
            })
    
    except Exception as e:
        issues.append({
            'type': 'filtering_logic_analysis_error',
            'error': str(e),
            'severity': 'medium'
        })
    
    return issues

def analyze_system_configuration():
    """ã‚·ã‚¹ãƒ†ãƒ è¨­å®šãƒ»ç’°å¢ƒå•é¡Œã®åˆ†æ"""
    print("ã‚·ã‚¹ãƒ†ãƒ è¨­å®šãƒ»ç’°å¢ƒåˆ†æé–‹å§‹...")
    
    config_issues = []
    
    # 1. è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ä¸€è²«æ€§ãƒã‚§ãƒƒã‚¯
    print("  1. è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä¸€è²«æ€§ãƒã‚§ãƒƒã‚¯")
    config_files = ['rccm-quiz-app/config.py', 'rccm-quiz-app/requirements.txt']
    for config_file in config_files:
        if os.path.exists(config_file):
            file_issues = check_config_file_integrity(config_file)
            config_issues.extend(file_issues)
    
    # 2. ç’°å¢ƒä¾å­˜ã®å•é¡Œãƒã‚§ãƒƒã‚¯
    print("  2. ç’°å¢ƒä¾å­˜å•é¡Œãƒã‚§ãƒƒã‚¯")
    env_issues = check_environment_dependencies()
    config_issues.extend(env_issues)
    
    return config_issues

def check_config_file_integrity(file_path):
    """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯"""
    issues = []
    
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        if 'config.py' in file_path:
            # ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰è¨­å®šãƒã‚§ãƒƒã‚¯
            if 'DEBUG = True' in content:
                issues.append({
                    'type': 'debug_mode_enabled',
                    'file': file_path,
                    'severity': 'medium'
                })
            
            # ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã‚­ãƒ¼è¨­å®šãƒã‚§ãƒƒã‚¯
            if 'SECRET_KEY' not in content:
                issues.append({
                    'type': 'missing_secret_key',
                    'file': file_path,
                    'severity': 'high'
                })
    
    except Exception as e:
        issues.append({
            'type': 'config_file_error',
            'file': file_path,
            'error': str(e),
            'severity': 'medium'
        })
    
    return issues

def check_environment_dependencies():
    """ç’°å¢ƒä¾å­˜å•é¡Œã®ãƒã‚§ãƒƒã‚¯"""
    issues = []
    
    # ãƒ‘ã‚¹åŒºåˆ‡ã‚Šæ–‡å­—ã®å•é¡Œãƒã‚§ãƒƒã‚¯
    app_py_path = "rccm-quiz-app/app.py"
    if os.path.exists(app_py_path):
        try:
            with open(app_py_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ‘ã‚¹åŒºåˆ‡ã‚Šæ–‡å­—ãƒã‚§ãƒƒã‚¯
            windows_paths = re.findall(r'[\'\"]\w+\\.*?[\'\"', content)
            unix_paths = re.findall(r'[\'\"]\w+/.*?[\'\"', content)
            
            if windows_paths:
                issues.append({
                    'type': 'hardcoded_windows_paths',
                    'paths': windows_paths[:5],  # æœ€åˆã®5å€‹ã®ã¿
                    'severity': 'medium'
                })
            
            if unix_paths:
                issues.append({
                    'type': 'hardcoded_unix_paths',
                    'paths': unix_paths[:5],
                    'severity': 'medium'
                })
        
        except Exception as e:
            issues.append({
                'type': 'environment_dependency_check_error',
                'error': str(e),
                'severity': 'low'
            })
    
    return issues

def analyze_data_pipeline():
    """ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼ãƒ»ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å•é¡Œã®åˆ†æ"""
    print("ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼ãƒ»ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³åˆ†æé–‹å§‹...")
    
    pipeline_issues = []
    
    # 1. ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ãƒ•ãƒ­ãƒ¼ãƒã‚§ãƒƒã‚¯
    print("  1. ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ãƒ•ãƒ­ãƒ¼ãƒã‚§ãƒƒã‚¯")
    load_issues = check_data_loading_pipeline()
    pipeline_issues.extend(load_issues)
    
    # 2. ãƒ¡ãƒ¢ãƒªä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒã‚§ãƒƒã‚¯
    print("  2. ãƒ¡ãƒ¢ãƒªä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒã‚§ãƒƒã‚¯")
    memory_issues = check_memory_usage_patterns()
    pipeline_issues.extend(memory_issues)
    
    return pipeline_issues

def check_data_loading_pipeline():
    """ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å•é¡Œãƒã‚§ãƒƒã‚¯"""
    issues = []
    
    app_py_path = "rccm-quiz-app/app.py"
    if os.path.exists(app_py_path):
        try:
            with open(app_py_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # åŒæœŸçš„ãªãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã®é »åº¦ãƒã‚§ãƒƒã‚¯
            csv_reads = len(re.findall(r'csv\.DictReader', content))
            file_opens = len(re.findall(r'open\s*\(.*?\.csv', content))
            
            if csv_reads > 10:
                issues.append({
                    'type': 'excessive_csv_reads',
                    'count': csv_reads,
                    'severity': 'medium'
                })
            
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ©Ÿæ§‹ã®å­˜åœ¨ãƒã‚§ãƒƒã‚¯
            cache_patterns = re.findall(r'cache|Cache', content)
            if len(cache_patterns) < 5 and csv_reads > 5:
                issues.append({
                    'type': 'insufficient_caching',
                    'csv_reads': csv_reads,
                    'cache_usage': len(cache_patterns),
                    'severity': 'high'
                })
        
        except Exception as e:
            issues.append({
                'type': 'pipeline_analysis_error',
                'error': str(e),
                'severity': 'medium'
            })
    
    return issues

def check_memory_usage_patterns():
    """ãƒ¡ãƒ¢ãƒªä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³å•é¡Œãƒã‚§ãƒƒã‚¯"""
    issues = []
    
    app_py_path = "rccm-quiz-app/app.py"
    if os.path.exists(app_py_path):
        try:
            with open(app_py_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # å¤§ããªãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®è“„ç©ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒã‚§ãƒƒã‚¯
            list_comprehensions = len(re.findall(r'\[.*?for.*?in.*?\]', content))
            large_loops = len(re.findall(r'for.*?in.*?range\(\d{3,}\)', content))
            
            if list_comprehensions > 20:
                issues.append({
                    'type': 'excessive_list_comprehensions',
                    'count': list_comprehensions,
                    'severity': 'medium'
                })
            
            if large_loops > 5:
                issues.append({
                    'type': 'large_range_loops',
                    'count': large_loops,
                    'severity': 'medium'
                })
        
        except Exception as e:
            issues.append({
                'type': 'memory_pattern_analysis_error',
                'error': str(e),
                'severity': 'low'
            })
    
    return issues

def analyze_system_interactions():
    """ã‚·ã‚¹ãƒ†ãƒ ç›¸äº’ä½œç”¨å•é¡Œã®åˆ†æ"""
    print("ã‚·ã‚¹ãƒ†ãƒ ç›¸äº’ä½œç”¨åˆ†æé–‹å§‹...")
    
    interaction_issues = []
    
    # 1. é–¢æ•°é–“ä¾å­˜é–¢ä¿‚ãƒã‚§ãƒƒã‚¯
    print("  1. é–¢æ•°é–“ä¾å­˜é–¢ä¿‚ãƒã‚§ãƒƒã‚¯")
    dependency_issues = check_function_dependencies()
    interaction_issues.extend(dependency_issues)
    
    # 2. ã‚°ãƒ­ãƒ¼ãƒãƒ«çŠ¶æ…‹ç®¡ç†ãƒã‚§ãƒƒã‚¯
    print("  2. ã‚°ãƒ­ãƒ¼ãƒãƒ«çŠ¶æ…‹ç®¡ç†ãƒã‚§ãƒƒã‚¯")
    global_state_issues = check_global_state_management()
    interaction_issues.extend(global_state_issues)
    
    return interaction_issues

def check_function_dependencies():
    """é–¢æ•°é–“ä¾å­˜é–¢ä¿‚å•é¡Œãƒã‚§ãƒƒã‚¯"""
    issues = []
    
    app_py_path = "rccm-quiz-app/app.py"
    if os.path.exists(app_py_path):
        try:
            with open(app_py_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # é–¢æ•°å®šç¾©ã¨å‘¼ã³å‡ºã—ã®åˆ†æ
            function_definitions = re.findall(r'def\s+(\w+)\s*\(', content)
            function_calls = re.findall(r'(\w+)\s*\(', content)
            
            # æœªå®šç¾©é–¢æ•°ã®å‘¼ã³å‡ºã—ãƒã‚§ãƒƒã‚¯ï¼ˆç°¡æ˜“ç‰ˆï¼‰
            undefined_calls = set(function_calls) - set(function_definitions) - set(['print', 'len', 'str', 'int', 'list', 'dict', 'open', 'range'])
            
            if len(undefined_calls) > 50:  # ã‚ã¾ã‚Šã«å¤šã„å ´åˆã¯å•é¡Œã®å¯èƒ½æ€§
                issues.append({
                    'type': 'potential_undefined_function_calls',
                    'count': len(undefined_calls),
                    'examples': list(undefined_calls)[:10],
                    'severity': 'medium'
                })
            
            # å¾ªç’°ä¾å­˜ã®ãƒªã‚¹ã‚¯ãƒã‚§ãƒƒã‚¯ï¼ˆdeptç³»é–¢æ•°ï¼‰
            dept_functions = [f for f in function_definitions if 'department' in f.lower()]
            if len(dept_functions) > 5:
                issues.append({
                    'type': 'complex_department_function_interdependency',
                    'function_count': len(dept_functions),
                    'functions': dept_functions,
                    'severity': 'medium'
                })
        
        except Exception as e:
            issues.append({
                'type': 'dependency_analysis_error',
                'error': str(e),
                'severity': 'low'
            })
    
    return issues

def check_global_state_management():
    """ã‚°ãƒ­ãƒ¼ãƒãƒ«çŠ¶æ…‹ç®¡ç†å•é¡Œãƒã‚§ãƒƒã‚¯"""
    issues = []
    
    app_py_path = "rccm-quiz-app/app.py"
    if os.path.exists(app_py_path):
        try:
            with open(app_py_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã®ä½¿ç”¨ãƒã‚§ãƒƒã‚¯
            global_vars = re.findall(r'^(\w+)\s*=', content, re.MULTILINE)
            global_statements = len(re.findall(r'global\s+\w+', content))
            
            if len(global_vars) > 20:
                issues.append({
                    'type': 'excessive_global_variables',
                    'count': len(global_vars),
                    'severity': 'medium'
                })
            
            if global_statements > 10:
                issues.append({
                    'type': 'excessive_global_statements',
                    'count': global_statements,
                    'severity': 'high'
                })
        
        except Exception as e:
            issues.append({
                'type': 'global_state_analysis_error',
                'error': str(e),
                'severity': 'low'
            })
    
    return issues

def analyze_architecture_design():
    """ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è¨­è¨ˆå•é¡Œã®åˆ†æ"""
    print("ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è¨­è¨ˆåˆ†æé–‹å§‹...")
    
    architecture_issues = []
    
    # 1. ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«æ§‹æˆãƒã‚§ãƒƒã‚¯
    print("  1. ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«æ§‹æˆãƒã‚§ãƒƒã‚¯")
    module_issues = check_module_structure()
    architecture_issues.extend(module_issues)
    
    # 2. è²¬ä»»åˆ†é›¢ãƒã‚§ãƒƒã‚¯
    print("  2. è²¬ä»»åˆ†é›¢ãƒã‚§ãƒƒã‚¯")
    separation_issues = check_separation_of_concerns()
    architecture_issues.extend(separation_issues)
    
    return architecture_issues

def check_module_structure():
    """ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«æ§‹æˆå•é¡Œãƒã‚§ãƒƒã‚¯"""
    issues = []
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã®åˆ†æ
    app_py_path = "rccm-quiz-app/app.py"
    if os.path.exists(app_py_path):
        try:
            file_size = os.path.getsize(app_py_path)
            with open(app_py_path, 'r', encoding='utf-8') as f:
                line_count = sum(1 for line in f)
            
            if file_size > 500000:  # 500KBä»¥ä¸Š
                issues.append({
                    'type': 'excessive_file_size',
                    'file': 'app.py',
                    'size_bytes': file_size,
                    'lines': line_count,
                    'severity': 'high'
                })
            
            if line_count > 10000:  # 10,000è¡Œä»¥ä¸Š
                issues.append({
                    'type': 'excessive_line_count',
                    'file': 'app.py',
                    'lines': line_count,
                    'severity': 'high'
                })
        
        except Exception as e:
            issues.append({
                'type': 'module_structure_analysis_error',
                'error': str(e),
                'severity': 'low'
            })
    
    return issues

def check_separation_of_concerns():
    """è²¬ä»»åˆ†é›¢å•é¡Œãƒã‚§ãƒƒã‚¯"""
    issues = []
    
    app_py_path = "rccm-quiz-app/app.py"
    if os.path.exists(app_py_path):
        try:
            with open(app_py_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«å†…ã§ã®å¤šæ§˜ãªè²¬ä»»ãƒã‚§ãƒƒã‚¯
            route_count = len(re.findall(r'@app\.route', content))
            class_count = len(re.findall(r'^class\s+\w+', content, re.MULTILINE))
            function_count = len(re.findall(r'^def\s+\w+', content, re.MULTILINE))
            
            if route_count > 50:
                issues.append({
                    'type': 'excessive_routes_in_single_file',
                    'count': route_count,
                    'severity': 'high'
                })
            
            if function_count > 200:
                issues.append({
                    'type': 'excessive_functions_in_single_file',
                    'count': function_count,
                    'severity': 'high'
                })
            
            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ­ã‚¸ãƒƒã‚¯ã¨ãƒ“ã‚¸ãƒã‚¹ãƒ­ã‚¸ãƒƒã‚¯ã®æ··åœ¨ãƒã‚§ãƒƒã‚¯
            db_operations = len(re.findall(r'\.csv|DictReader|\.json', content))
            route_logic = len(re.findall(r'request\.|session\[', content))
            
            if db_operations > 20 and route_logic > 20:
                issues.append({
                    'type': 'mixed_data_and_presentation_logic',
                    'db_operations': db_operations,
                    'route_logic': route_logic,
                    'severity': 'medium'
                })
        
        except Exception as e:
            issues.append({
                'type': 'separation_analysis_error',
                'error': str(e),
                'severity': 'low'
            })
    
    return issues

def synthesize_root_causes(analysis_results):
    """æ ¹æœ¬åŸå› ã®çµ±åˆåˆ†æã¨å„ªå…ˆåº¦ä»˜ã‘"""
    print("\n" + "=" * 100)
    print("ğŸ¯ å¤šé‡æ ¹æœ¬åŸå› çµ±åˆåˆ†æçµæœï¼ˆã‚¦ãƒ«ãƒˆãƒ©ã‚·ãƒ³ã‚¯ãƒ»çµ¶å¯¾ã«å˜˜ã‚’ã¤ã‹ãªã„ï¼‰")
    print("=" * 100)
    
    all_issues = []
    
    # å…¨ã¦ã®å•é¡Œã‚’åé›†
    for category, issues in analysis_results.items():
        if isinstance(issues, list) and category.endswith('_issues'):
            for issue in issues:
                issue['category'] = category
                all_issues.append(issue)
    
    # æ·±åˆ»åº¦åˆ¥ã«åˆ†é¡
    critical_issues = [i for i in all_issues if i.get('severity') == 'critical']
    high_issues = [i for i in all_issues if i.get('severity') == 'high']
    medium_issues = [i for i in all_issues if i.get('severity') == 'medium']
    low_issues = [i for i in all_issues if i.get('severity') == 'low']
    
    print(f"\nğŸ“Š ç™ºè¦‹ã•ã‚ŒãŸå•é¡Œã®çµ±è¨ˆ:")
    print(f"  ğŸš¨ CRITICAL (æœ€å„ªå…ˆ): {len(critical_issues)}å€‹")
    print(f"  âš ï¸  HIGH (é«˜å„ªå…ˆåº¦): {len(high_issues)}å€‹")
    print(f"  ğŸ“‹ MEDIUM (ä¸­å„ªå…ˆåº¦): {len(medium_issues)}å€‹")
    print(f"  â„¹ï¸  LOW (ä½å„ªå…ˆåº¦): {len(low_issues)}å€‹")
    print(f"  ğŸ“ˆ ç·å•é¡Œæ•°: {len(all_issues)}å€‹")
    
    print(f"\nğŸš¨ CRITICALå•é¡Œï¼ˆå³åº§ã«ä¿®æ­£ãŒå¿…è¦ï¼‰:")
    for issue in critical_issues:
        print(f"  - {issue['type']}: {issue.get('description', str(issue))}")
    
    print(f"\nâš ï¸ HIGHå„ªå…ˆåº¦å•é¡Œï¼ˆ2é€±é–“æ²»ã‚‰ãªã„ä¸»è¦åŸå› ï¼‰:")
    for issue in high_issues[:10]:  # æœ€åˆã®10å€‹ã®ã¿è¡¨ç¤º
        print(f"  - {issue['type']}: {issue.get('description', str(issue))}")
    
    # æ ¹æœ¬åŸå› ã®ç›¸äº’é–¢ä¿‚åˆ†æ
    problem_clusters = analyze_problem_clusters(all_issues)
    
    print(f"\nğŸ”— å•é¡Œã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼åˆ†æï¼ˆç›¸äº’é–¢ä¿‚ã®ã‚ã‚‹å•é¡Œç¾¤ï¼‰:")
    for cluster_name, cluster_issues in problem_clusters.items():
        print(f"  {cluster_name}: {len(cluster_issues)}å€‹ã®é–¢é€£å•é¡Œ")
    
    # æœ€çµ‚æ¨å¥¨äº‹é …
    recommendations = generate_comprehensive_recommendations(all_issues, problem_clusters)
    
    print(f"\nğŸ“‹ åŒ…æ‹¬çš„ä¿®æ­£æ¨å¥¨äº‹é …ï¼ˆå„ªå…ˆåº¦é †ï¼‰:")
    for i, rec in enumerate(recommendations, 1):
        print(f"  {i}. {rec}")
    
    return {
        'total_issues': len(all_issues),
        'critical_issues': len(critical_issues),
        'high_issues': len(high_issues),
        'problem_clusters': problem_clusters,
        'recommendations': recommendations
    }

def analyze_problem_clusters(all_issues):
    """å•é¡Œã®ç›¸äº’é–¢ä¿‚ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼åˆ†æ"""
    clusters = {
        'ãƒ‡ãƒ¼ã‚¿å“è³ªã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼': [],
        'ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼': [],
        'ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼': [],
        'ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼': []
    }
    
    for issue in all_issues:
        issue_type = issue.get('type', '')
        
        if any(keyword in issue_type for keyword in ['encoding', 'duplicate', 'quality', 'inconsistent']):
            clusters['ãƒ‡ãƒ¼ã‚¿å“è³ªã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼'].append(issue)
        elif any(keyword in issue_type for keyword in ['excessive', 'memory', 'caching', 'loop']):
            clusters['ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼'].append(issue)
        elif any(keyword in issue_type for keyword in ['file_size', 'complexity', 'separation', 'module']):
            clusters['ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼'].append(issue)
        elif any(keyword in issue_type for keyword in ['error', 'exception', 'handling']):
            clusters['ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼'].append(issue)
    
    return clusters

def generate_comprehensive_recommendations(all_issues, problem_clusters):
    """åŒ…æ‹¬çš„ä¿®æ­£æ¨å¥¨äº‹é …ã®ç”Ÿæˆ"""
    recommendations = []
    
    # å•é¡Œã®æ·±åˆ»åº¦ã¨æ•°ã«åŸºã¥ãæ¨å¥¨äº‹é …
    critical_count = len([i for i in all_issues if i.get('severity') == 'critical'])
    high_count = len([i for i in all_issues if i.get('severity') == 'high'])
    
    if critical_count > 0:
        recommendations.append(f"ç·Šæ€¥ä¿®æ­£: {critical_count}å€‹ã®CRITICALå•é¡Œã‚’æœ€å„ªå…ˆã§ä¿®æ­£")
    
    if high_count > 10:
        recommendations.append(f"åŒ…æ‹¬çš„ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°: {high_count}å€‹ã®HIGHå•é¡Œã¯æ ¹æœ¬çš„ãªè¨­è¨ˆè¦‹ç›´ã—ãŒå¿…è¦")
    
    # ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼åˆ¥æ¨å¥¨äº‹é …
    for cluster_name, cluster_issues in problem_clusters.items():
        if len(cluster_issues) > 5:
            if 'ãƒ‡ãƒ¼ã‚¿å“è³ª' in cluster_name:
                recommendations.append("ãƒ‡ãƒ¼ã‚¿å“è³ªç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã®å°å…¥ã¨ãƒ‡ãƒ¼ã‚¿æ­£è¦åŒ–")
            elif 'ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹' in cluster_name:
                recommendations.append("ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚·ã‚¹ãƒ†ãƒ å°å…¥ã¨ã‚¯ã‚¨ãƒªæœ€é©åŒ–")
            elif 'ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£' in cluster_name:
                recommendations.append("ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹åŒ–ã¾ãŸã¯ãƒ¢ã‚¸ãƒ¥ãƒ©ãƒ¼è¨­è¨ˆã¸ã®ç§»è¡Œ")
            elif 'ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°' in cluster_name:
                recommendations.append("çµ±ä¸€çš„ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°æˆ¦ç•¥ã®å®Ÿè£…")
    
    # ç·åˆçš„æ¨å¥¨äº‹é …
    if len(all_issues) > 50:
        recommendations.append("æ®µéšçš„ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°è¨ˆç”»ã®ç­–å®šï¼ˆ3-6ã‹æœˆï¼‰")
        recommendations.append("è‡ªå‹•ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆã®æ§‹ç¯‰")
        recommendations.append("ç¶™ç¶šçš„å“è³ªç›£è¦–ã‚·ã‚¹ãƒ†ãƒ ã®å°å…¥")
    
    return recommendations

if __name__ == "__main__":
    result = comprehensive_multi_root_cause_analysis()