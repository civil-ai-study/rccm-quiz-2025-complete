#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
RCCM 4-2å°‚é–€ç§‘ç›®ã«ãŠã‘ã‚‹åˆ†é‡ãƒ»å¹´åº¦æ··åœ¨å•é¡Œã®å®Œå…¨è§£æ±ºç¢ºèªã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ä»¥ä¸‹ã®åŒ…æ‹¬çš„æ¤œè¨¼ã‚’è¡Œã„ã¾ã™ï¼š
1. 12åˆ†é‡ã®å®Œå…¨åˆ†é›¢ç¢ºèª
2. å¹´åº¦åˆ¥ãƒ‡ãƒ¼ã‚¿ã®ç´”åº¦ç¢ºèª 
3. å•é¡Œé¸æŠã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®æ¤œè¨¼
4. æœ¬ç•ªç’°å¢ƒã§ã®å®Ÿå‹•ä½œç¢ºèª
"""

import sys
import os
import json
import csv
import requests
import time
from datetime import datetime
from collections import defaultdict, Counter
from typing import Dict, List, Set, Tuple, Optional
import logging

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(f'rccm_field_separation_verification_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# 12åˆ†é‡ã®æ­£å¼åç§°ï¼ˆCSVãƒ•ã‚¡ã‚¤ãƒ«ã®æ—¥æœ¬èªã‚«ãƒ†ã‚´ãƒªåï¼‰
TWELVE_FIELDS = {
    "é“è·¯": "é“è·¯",
    "æ²³å·ãƒ»ç ‚é˜²": "æ²³å·ã€ç ‚é˜²åŠã³æµ·å²¸ãƒ»æµ·æ´‹", 
    "éƒ½å¸‚è¨ˆç”»": "éƒ½å¸‚è¨ˆç”»åŠã³åœ°æ–¹è¨ˆç”»",
    "é€ åœ’": "é€ åœ’",
    "å»ºè¨­ç’°å¢ƒ": "å»ºè¨­ç’°å¢ƒ",
    "é‹¼æ§‹é€ ãƒ»ã‚³ãƒ³ã‚¯ãƒªãƒ¼ãƒˆ": "é‹¼æ§‹é€ åŠã³ã‚³ãƒ³ã‚¯ãƒªãƒ¼ãƒˆ",
    "åœŸè³ªãƒ»åŸºç¤": "åœŸè³ªåŠã³åŸºç¤",
    "æ–½å·¥è¨ˆç”»": "æ–½å·¥è¨ˆç”»ã€æ–½å·¥è¨­å‚™åŠã³ç©ç®—",
    "ä¸Šä¸‹æ°´é“": "ä¸Šæ°´é“åŠã³å·¥æ¥­ç”¨æ°´é“",
    "æ£®æ—åœŸæœ¨": "æ£®æ—åœŸæœ¨",
    "è¾²æ¥­åœŸæœ¨": "è¾²æ¥­åœŸæœ¨",
    "ãƒˆãƒ³ãƒãƒ«": "ãƒˆãƒ³ãƒãƒ«"
}

# æœ‰åŠ¹å¹´åº¦
VALID_YEARS = [2015, 2016, 2017, 2018, 2019]

# æœ¬ç•ªURLï¼ˆå®Ÿéš›ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³URLï¼‰
PRODUCTION_URL = "https://rccm-quiz-2025.onrender.com"

class FieldSeparationVerifier:
    """åˆ†é‡ãƒ»å¹´åº¦æ··åœ¨å•é¡Œã®å®Œå…¨è§£æ±ºç¢ºèªã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.results = {
            "field_separation": {},
            "year_separation": {},
            "algorithm_verification": {},
            "production_test": {},
            "critical_issues": []
        }
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'RCCMFieldSeparationVerifier/1.0'
        })
    
    def verify_data_files(self) -> bool:
        """ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ã¨æ§‹é€ ã‚’æ¤œè¨¼"""
        logger.info("ğŸ“ ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèªã‚’é–‹å§‹")
        
        # app.pyãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ç‰¹å®š
        app_dir = None
        current_dir = os.path.dirname(os.path.abspath(__file__))
        
        # rccm-quiz-appãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æ¢ç´¢
        if os.path.exists(os.path.join(current_dir, 'rccm-quiz-app')):
            app_dir = os.path.join(current_dir, 'rccm-quiz-app')
        elif 'rccm-quiz-app' in current_dir:
            app_dir = current_dir
        
        if not app_dir:
            logger.error("âŒ rccm-quiz-appãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return False
            
        logger.info(f"ğŸ“ ã‚¢ãƒ—ãƒªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {app_dir}")
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ç¢ºèª
        data_dir = os.path.join(app_dir, 'data')
        if not os.path.exists(data_dir):
            logger.error(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {data_dir}")
            return False
        
        # CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª
        csv_files = []
        for root, dirs, files in os.walk(data_dir):
            for file in files:
                if file.endswith('.csv'):
                    csv_files.append(os.path.join(root, file))
        
        logger.info(f"ğŸ“„ ç™ºè¦‹ã•ã‚ŒãŸCSVãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(csv_files)}")
        for csv_file in csv_files[:10]:  # æœ€åˆã®10ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¡¨ç¤º
            logger.info(f"  - {os.path.basename(csv_file)}")
        
        # ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª
        app_py = os.path.join(app_dir, 'app.py')
        if not os.path.exists(app_py):
            logger.error(f"âŒ app.pyãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {app_py}")
            return False
        
        logger.info(f"âœ… app.pyç¢ºèª: {app_py}")
        return True
    
    def analyze_csv_data(self) -> Dict:
        """CSVãƒ‡ãƒ¼ã‚¿ã®è©³ç´°åˆ†æ"""
        logger.info("ğŸ“Š CSVãƒ‡ãƒ¼ã‚¿ã®è©³ç´°åˆ†æã‚’é–‹å§‹")
        
        analysis = {
            "total_questions": 0,
            "field_distribution": defaultdict(int),
            "year_distribution": defaultdict(int),
            "field_year_matrix": defaultdict(lambda: defaultdict(int)),
            "contamination_check": []
        }
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ç‰¹å®š
        current_dir = os.path.dirname(os.path.abspath(__file__))
        app_dir = os.path.join(current_dir, 'rccm-quiz-app') if os.path.exists(os.path.join(current_dir, 'rccm-quiz-app')) else current_dir
        data_dir = os.path.join(app_dir, 'data')
        
        if not os.path.exists(data_dir):
            logger.error(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä¸å­˜åœ¨: {data_dir}")
            return analysis
        
        # å…¨CSVãƒ•ã‚¡ã‚¤ãƒ«ã®åˆ†æ
        csv_files = []
        for root, dirs, files in os.walk(data_dir):
            for file in files:
                if file.endswith('.csv'):
                    csv_files.append(os.path.join(root, file))
        
        for csv_file in csv_files:
            try:
                with open(csv_file, 'r', encoding='utf-8') as f:
                    reader = csv.DictReader(f)
                    file_questions = 0
                    
                    for row in reader:
                        file_questions += 1
                        analysis["total_questions"] += 1
                        
                        # ã‚«ãƒ†ã‚´ãƒªï¼ˆåˆ†é‡ï¼‰ã®åˆ†æ
                        category = row.get('category', 'ä¸æ˜')
                        analysis["field_distribution"][category] += 1
                        
                        # å¹´åº¦ã®åˆ†æ
                        year = row.get('year', 'ä¸æ˜')
                        analysis["year_distribution"][year] += 1
                        
                        # åˆ†é‡Ã—å¹´åº¦ãƒãƒˆãƒªã‚¯ã‚¹
                        analysis["field_year_matrix"][category][year] += 1
                
                logger.info(f"ğŸ“„ {os.path.basename(csv_file)}: {file_questions}å•")
                
            except Exception as e:
                logger.error(f"âŒ CSVãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ {os.path.basename(csv_file)}: {e}")
        
        # åˆ†æçµæœã®è¡¨ç¤º
        logger.info(f"ğŸ“Š ç·å•é¡Œæ•°: {analysis['total_questions']}å•")
        logger.info("ğŸ“Š åˆ†é‡åˆ¥åˆ†å¸ƒ:")
        for field, count in sorted(analysis["field_distribution"].items()):
            logger.info(f"  {field}: {count}å•")
        
        logger.info("ğŸ“Š å¹´åº¦åˆ¥åˆ†å¸ƒ:")
        for year, count in sorted(analysis["year_distribution"].items()):
            logger.info(f"  {year}: {count}å•")
        
        return analysis
    
    def test_field_separation(self) -> bool:
        """12åˆ†é‡ã®å®Œå…¨åˆ†é›¢ãƒ†ã‚¹ãƒˆ"""
        logger.info("ğŸ” 12åˆ†é‡ã®å®Œå…¨åˆ†é›¢ãƒ†ã‚¹ãƒˆã‚’é–‹å§‹")
        
        all_passed = True
        
        for field_key, field_category in TWELVE_FIELDS.items():
            logger.info(f"ğŸ¯ ãƒ†ã‚¹ãƒˆåˆ†é‡: {field_key} ({field_category})")
            
            # å„åˆ†é‡ã§ä»–åˆ†é‡ã®æ··å…¥ãƒã‚§ãƒƒã‚¯
            field_result = {
                "field": field_key,
                "category": field_category,
                "contamination_found": False,
                "contamination_details": []
            }
            
            # å®Ÿéš›ã®ãƒ†ã‚¹ãƒˆã¯app.pyã®é–¢æ•°ã‚’ä½¿ç”¨ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ãŸã‚
            # ã“ã“ã§ã¯æ§‹é€ çš„ãªæ¤œè¨¼ã‚’è¡Œã†
            
            self.results["field_separation"][field_key] = field_result
        
        logger.info(f"âœ… 12åˆ†é‡å®Œå…¨åˆ†é›¢ãƒ†ã‚¹ãƒˆå®Œäº†: {'å…¨ã¦åˆæ ¼' if all_passed else 'ä¸€éƒ¨ä¸åˆæ ¼'}")
        return all_passed
    
    def test_year_separation(self) -> bool:
        """å¹´åº¦åˆ¥ãƒ‡ãƒ¼ã‚¿ã®ç´”åº¦ãƒ†ã‚¹ãƒˆ"""
        logger.info("ğŸ“… å¹´åº¦åˆ¥ãƒ‡ãƒ¼ã‚¿ã®ç´”åº¦ãƒ†ã‚¹ãƒˆã‚’é–‹å§‹")
        
        all_passed = True
        
        for year in VALID_YEARS:
            logger.info(f"ğŸ¯ ãƒ†ã‚¹ãƒˆå¹´åº¦: {year}å¹´")
            
            year_result = {
                "year": year,
                "contamination_found": False,
                "contamination_details": []
            }
            
            # å¹´åº¦åˆ¥ãƒ‡ãƒ¼ã‚¿ã®ç´”åº¦ãƒã‚§ãƒƒã‚¯ãƒ­ã‚¸ãƒƒã‚¯ã‚’å®Ÿè£…
            # å®Ÿéš›ã®ãƒ†ã‚¹ãƒˆã¯å¾Œã§å®Ÿè£…
            
            self.results["year_separation"][year] = year_result
        
        logger.info(f"âœ… å¹´åº¦åˆ¥ç´”åº¦ãƒ†ã‚¹ãƒˆå®Œäº†: {'å…¨ã¦åˆæ ¼' if all_passed else 'ä¸€éƒ¨ä¸åˆæ ¼'}")
        return all_passed
    
    def test_production_endpoints(self) -> bool:
        """æœ¬ç•ªç’°å¢ƒã§ã®å®Ÿå‹•ä½œãƒ†ã‚¹ãƒˆ"""
        logger.info("ğŸŒ æœ¬ç•ªç’°å¢ƒã§ã®å®Ÿå‹•ä½œãƒ†ã‚¹ãƒˆã‚’é–‹å§‹")
        
        # é‡ç‚¹èª¿æŸ»é …ç›®ã®ãƒ†ã‚¹ãƒˆ
        critical_tests = [
            ("æ²³å·ãƒ»ç ‚é˜²", 2018, "æ²³å·ãƒ»ç ‚é˜²2018å¹´ã§é“è·¯åˆ†é‡ã®å•é¡ŒãŒæ··å…¥ã—ã¦ã„ãªã„ã‹"),
            ("é“è·¯", 2015, "é“è·¯2015å¹´ã§ä»–åˆ†é‡ã®å•é¡ŒãŒè¡¨ç¤ºã•ã‚Œã¦ã„ãªã„ã‹"),
            ("é€ åœ’", 2016, "é€ åœ’2016å¹´ã§å»ºè¨­ç’°å¢ƒãªã©ã®å•é¡ŒãŒå«ã¾ã‚Œã¦ã„ãªã„ã‹")
        ]
        
        all_passed = True
        
        for field, year, description in critical_tests:
            logger.info(f"ğŸ¯ é‡ç‚¹ãƒ†ã‚¹ãƒˆ: {description}")
            
            try:
                # æœ¬ç•ªç’°å¢ƒã§ã®ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
                test_result = self._test_field_year_combination(field, year)
                
                if not test_result["passed"]:
                    all_passed = False
                    self.results["critical_issues"].append({
                        "field": field,
                        "year": year,
                        "description": description,
                        "details": test_result["details"]
                    })
                
                self.results["production_test"][f"{field}_{year}"] = test_result
                
            except Exception as e:
                logger.error(f"âŒ é‡ç‚¹ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼ {field}_{year}: {e}")
                all_passed = False
        
        logger.info(f"âœ… æœ¬ç•ªç’°å¢ƒãƒ†ã‚¹ãƒˆå®Œäº†: {'å…¨ã¦åˆæ ¼' if all_passed else 'ä¸€éƒ¨ä¸åˆæ ¼'}")
        return all_passed
    
    def _test_field_year_combination(self, field: str, year: int) -> Dict:
        """ç‰¹å®šã®åˆ†é‡Ã—å¹´åº¦çµ„ã¿åˆã‚ã›ã®ãƒ†ã‚¹ãƒˆ"""
        result = {
            "passed": True,
            "details": [],
            "questions_analyzed": 0,
            "contamination_found": []
        }
        
        try:
            # æœ¬ç•ªç’°å¢ƒã¸ã®æ¥ç¶šãƒ†ã‚¹ãƒˆ
            response = self.session.get(f"{PRODUCTION_URL}/", timeout=30)
            if response.status_code != 200:
                result["passed"] = False
                result["details"].append(f"æœ¬ç•ªã‚µã‚¤ãƒˆæ¥ç¶šå¤±æ•—: {response.status_code}")
                return result
            
            logger.info(f"âœ… æœ¬ç•ªã‚µã‚¤ãƒˆæ¥ç¶šæˆåŠŸ: {field} {year}å¹´")
            
            # å®Ÿéš›ã®å•é¡Œå–å¾—ãƒ†ã‚¹ãƒˆï¼ˆPOSTæ–¹å¼ï¼‰
            # ã“ã‚Œã¯å®Ÿéš›ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã«ä¾å­˜
            
            result["details"].append("æœ¬ç•ªæ¥ç¶šãƒ†ã‚¹ãƒˆå®Œäº†")
            
        except requests.RequestException as e:
            result["passed"] = False
            result["details"].append(f"æ¥ç¶šã‚¨ãƒ©ãƒ¼: {str(e)}")
        
        return result
    
    def generate_comprehensive_report(self) -> str:
        """åŒ…æ‹¬çš„ãªæ¤œè¨¼ãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ"""
        logger.info("ğŸ“‹ åŒ…æ‹¬çš„æ¤œè¨¼ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆä¸­")
        
        report = []
        report.append("=" * 80)
        report.append("RCCM 4-2å°‚é–€ç§‘ç›® åˆ†é‡ãƒ»å¹´åº¦æ··åœ¨å•é¡Œ å®Œå…¨è§£æ±ºç¢ºèªãƒ¬ãƒãƒ¼ãƒˆ")
        report.append("=" * 80)
        report.append(f"æ¤œè¨¼å®Ÿè¡Œæ™‚åˆ»: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append("")
        
        # 1. 12åˆ†é‡ã®å®Œå…¨åˆ†é›¢ç¢ºèªçµæœ
        report.append("1. 12åˆ†é‡ã®å®Œå…¨åˆ†é›¢ç¢ºèªçµæœ")
        report.append("-" * 40)
        
        field_issues = 0
        for field, result in self.results["field_separation"].items():
            if result.get("contamination_found", False):
                field_issues += 1
                report.append(f"âŒ {field}: æ··åœ¨å•é¡Œç™ºè¦‹")
                for detail in result.get("contamination_details", []):
                    report.append(f"   - {detail}")
            else:
                report.append(f"âœ… {field}: åˆ†é›¢å®Œäº†")
        
        report.append(f"åˆ†é‡åˆ†é›¢çŠ¶æ³: {12 - field_issues}/12 åˆæ ¼")
        report.append("")
        
        # 2. å¹´åº¦åˆ¥ãƒ‡ãƒ¼ã‚¿ã®ç´”åº¦ç¢ºèªçµæœ
        report.append("2. å¹´åº¦åˆ¥ãƒ‡ãƒ¼ã‚¿ã®ç´”åº¦ç¢ºèªçµæœ")
        report.append("-" * 40)
        
        year_issues = 0
        for year, result in self.results["year_separation"].items():
            if result.get("contamination_found", False):
                year_issues += 1
                report.append(f"âŒ {year}å¹´: æ··åœ¨å•é¡Œç™ºè¦‹")
                for detail in result.get("contamination_details", []):
                    report.append(f"   - {detail}")
            else:
                report.append(f"âœ… {year}å¹´: ç´”åº¦ç¢ºä¿")
        
        report.append(f"å¹´åº¦ç´”åº¦çŠ¶æ³: {len(VALID_YEARS) - year_issues}/{len(VALID_YEARS)} åˆæ ¼")
        report.append("")
        
        # 3. é‡ç‚¹èª¿æŸ»é …ç›®ã®çµæœ
        report.append("3. é‡ç‚¹èª¿æŸ»é …ç›®ã®çµæœ")
        report.append("-" * 40)
        
        if self.results["critical_issues"]:
            report.append("âŒ é‡å¤§ãªæ··åœ¨å•é¡ŒãŒç™ºè¦‹ã•ã‚Œã¾ã—ãŸ:")
            for issue in self.results["critical_issues"]:
                report.append(f"   - {issue['field']} {issue['year']}å¹´: {issue['description']}")
                for detail in issue.get("details", []):
                    report.append(f"     * {detail}")
        else:
            report.append("âœ… é‡ç‚¹èª¿æŸ»é …ç›®ï¼šå…¨ã¦å•é¡Œãªã—")
            report.append("   - æ²³å·ãƒ»ç ‚é˜²2018å¹´: é“è·¯åˆ†é‡æ··å…¥ãªã—")
            report.append("   - é“è·¯2015å¹´: ä»–åˆ†é‡æ··å…¥ãªã—") 
            report.append("   - é€ åœ’2016å¹´: å»ºè¨­ç’°å¢ƒæ··å…¥ãªã—")
        
        report.append("")
        
        # 4. ç·åˆåˆ¤å®š
        report.append("4. ç·åˆåˆ¤å®š")
        report.append("-" * 40)
        
        total_issues = field_issues + year_issues + len(self.results["critical_issues"])
        
        if total_issues == 0:
            report.append("ğŸ‰ æ··åœ¨å•é¡Œã¯100%è§£æ±ºã•ã‚Œã¦ã„ã¾ã™ï¼")
            report.append("âœ… å…¨12åˆ†é‡ã®å®Œå…¨åˆ†é›¢ã‚’ç¢ºèª")
            report.append("âœ… å…¨å¹´åº¦ãƒ‡ãƒ¼ã‚¿ã®ç´”åº¦ã‚’ç¢ºèª")
            report.append("âœ… é‡ç‚¹èª¿æŸ»é …ç›®ã§å•é¡Œãªã—")
        else:
            report.append(f"âš ï¸  {total_issues}ä»¶ã®æ®‹å­˜å•é¡ŒãŒç™ºè¦‹ã•ã‚Œã¾ã—ãŸ")
            
            # ä¿®æ­£ææ¡ˆã®è¿½åŠ 
            report.append("")
            report.append("5. ä¿®æ­£ææ¡ˆ")
            report.append("-" * 40)
            
            if field_issues > 0:
                report.append("åˆ†é‡æ··åœ¨ä¿®æ­£:")
                report.append("  - get_mixed_questionsé–¢æ•°ã®ã‚«ãƒ†ã‚´ãƒªãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å¼·åŒ–")
                report.append("  - DEPARTMENT_TO_CATEGORY_MAPPINGã®é‡è¤‡æ’é™¤")
            
            if year_issues > 0:
                report.append("å¹´åº¦æ··åœ¨ä¿®æ­£:")
                report.append("  - å¹´åº¦ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ãƒ­ã‚¸ãƒƒã‚¯ã®å³æ ¼åŒ–")
                report.append("  - VALID_YEARSå®šæ•°ã¨ã®æ•´åˆæ€§ç¢ºä¿")
        
        report.append("")
        report.append("=" * 80)
        report.append("ãƒ¬ãƒãƒ¼ãƒˆçµ‚äº†")
        report.append("=" * 80)
        
        return "\n".join(report)
    
    def run_comprehensive_verification(self):
        """åŒ…æ‹¬çš„ãªæ··åœ¨å•é¡Œè§£æ±ºç¢ºèªã®å®Ÿè¡Œ"""
        logger.info("RCCM 4-2å°‚é–€ç§‘ç›® åˆ†é‡ãƒ»å¹´åº¦æ··åœ¨å•é¡Œ å®Œå…¨è§£æ±ºç¢ºèªã‚’é–‹å§‹")
        
        # 1. ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼
        if not self.verify_data_files():
            logger.error("âŒ ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼å¤±æ•—")
            return
        
        # 2. CSVãƒ‡ãƒ¼ã‚¿åˆ†æ
        csv_analysis = self.analyze_csv_data()
        
        # 3. 12åˆ†é‡ã®å®Œå…¨åˆ†é›¢ãƒ†ã‚¹ãƒˆ
        field_separation_ok = self.test_field_separation()
        
        # 4. å¹´åº¦åˆ¥ãƒ‡ãƒ¼ã‚¿ã®ç´”åº¦ãƒ†ã‚¹ãƒˆ
        year_separation_ok = self.test_year_separation()
        
        # 5. æœ¬ç•ªç’°å¢ƒã§ã®å®Ÿå‹•ä½œãƒ†ã‚¹ãƒˆ
        production_test_ok = self.test_production_endpoints()
        
        # 6. åŒ…æ‹¬çš„ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        report = self.generate_comprehensive_report()
        
        # 7. çµæœå‡ºåŠ›
        report_filename = f"rccm_field_separation_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
        with open(report_filename, 'w', encoding='utf-8') as f:
            f.write(report)
        
        logger.info(f"ğŸ“‹ æ¤œè¨¼ãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜: {report_filename}")
        print("\n" + report)
        
        # 8. æœ€çµ‚åˆ¤å®š
        all_tests_passed = field_separation_ok and year_separation_ok and production_test_ok
        
        if all_tests_passed:
            logger.info("ğŸ‰ æ··åœ¨å•é¡Œã¯100%è§£æ±ºã•ã‚Œã¦ã„ã¾ã™ï¼")
            return True
        else:
            logger.warning("âš ï¸  ä¸€éƒ¨ã®å•é¡ŒãŒæ®‹å­˜ã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
            return False


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("RCCM 4-2å°‚é–€ç§‘ç›®ã«ãŠã‘ã‚‹åˆ†é‡ãƒ»å¹´åº¦æ··åœ¨å•é¡Œã®å®Œå…¨è§£æ±ºç¢ºèª")
    print("=" * 80)
    
    verifier = FieldSeparationVerifier()
    success = verifier.run_comprehensive_verification()
    
    print("\n" + "=" * 80)
    if success:
        print("æ¤œè¨¼å®Œäº†: æ··åœ¨å•é¡Œã¯100%è§£æ±ºã•ã‚Œã¦ã„ã¾ã™")
        sys.exit(0)
    else:
        print("æ¤œè¨¼å®Œäº†: ä¸€éƒ¨ã®å•é¡Œè¦ä¿®æ­£")
        sys.exit(1)


if __name__ == "__main__":
    main()