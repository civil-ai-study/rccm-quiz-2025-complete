#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
RCCMè©¦é¨“å•é¡Œé›†ã‚¢ãƒ—ãƒª - å…¨12åˆ†é‡ã‚«ãƒ†ã‚´ãƒªåçµ±ä¸€æ€§æ¤œè¨¼ãƒ„ãƒ¼ãƒ«

è©³ç´°æ¤œè¨¼é …ç›®ï¼š
1. å…¨12åˆ†é‡ã®å„å¹´åº¦CSVãƒ•ã‚¡ã‚¤ãƒ«ã§ã®ã‚«ãƒ†ã‚´ãƒªåè¡¨è¨˜çµ±ä¸€æ€§
2. å¾®å¦™ãªè¡¨è¨˜æºã‚Œï¼ˆå¥èª­ç‚¹ã€ã‚¹ãƒšãƒ¼ã‚¹ã€è¡¨è¨˜é•ã„ï¼‰ã®æ¤œå‡º
3. app.pyã®DEPARTMENT_TO_CATEGORY_MAPPINGã¨CSVãƒ‡ãƒ¼ã‚¿ã®æ•´åˆæ€§
4. å„åˆ†é‡ã§å¹´åº¦ã«ã‚ˆã£ã¦ã‚«ãƒ†ã‚´ãƒªåãŒå¤‰ã‚ã£ã¦ã„ãªã„ã‹
"""

import os
import csv
import pandas as pd
from collections import defaultdict, Counter
import re
import json
from datetime import datetime

class ComprehensiveCategoryChecker:
    def __init__(self, data_dir):
        self.data_dir = data_dir
        self.all_categories = defaultdict(list)  # åˆ†é‡åˆ¥ã‚«ãƒ†ã‚´ãƒªãƒªã‚¹ãƒˆ
        self.category_variations = defaultdict(set)  # ã‚«ãƒ†ã‚´ãƒªã®è¡¨è¨˜æºã‚Œ
        self.year_analysis = defaultdict(dict)  # å¹´åº¦åˆ¥åˆ†æ
        self.inconsistencies = []  # ä¸æ•´åˆãƒªã‚¹ãƒˆ
        
        # app.pyã‹ã‚‰å–å¾—ã—ãŸ12åˆ†é‡ã®æ­£å¼ãƒãƒƒãƒ”ãƒ³ã‚°
        self.official_mapping = {
            'road': 'é“è·¯',
            'tunnel': 'ãƒˆãƒ³ãƒãƒ«',
            'civil_planning': 'æ²³å·ã€ç ‚é˜²åŠã³æµ·å²¸ãƒ»æµ·æ´‹',
            'urban_planning': 'éƒ½å¸‚è¨ˆç”»åŠã³åœ°æ–¹è¨ˆç”»',
            'landscape': 'é€ åœ’',
            'construction_env': 'å»ºè¨­ç’°å¢ƒ',
            'steel_concrete': 'é‹¼æ§‹é€ åŠã³ã‚³ãƒ³ã‚¯ãƒªãƒ¼ãƒˆ',
            'soil_foundation': 'åœŸè³ªåŠã³åŸºç¤',
            'construction_planning': 'æ–½å·¥è¨ˆç”»ã€æ–½å·¥è¨­å‚™åŠã³ç©ç®—',
            'water_supply': 'ä¸Šæ°´é“åŠã³å·¥æ¥­ç”¨æ°´é“',
            'forestry': 'æ£®æ—åœŸæœ¨',
            'agriculture': 'è¾²æ¥­åœŸæœ¨'
        }
        
        # 12åˆ†é‡ã®æ­£å¼ã‚«ãƒ†ã‚´ãƒªå
        self.official_categories = set(self.official_mapping.values())
        
        print("ğŸ” å…¨12åˆ†é‡ã‚«ãƒ†ã‚´ãƒªåçµ±ä¸€æ€§æ¤œè¨¼é–‹å§‹")
        print(f"å¯¾è±¡åˆ†é‡: {len(self.official_categories)}åˆ†é‡")
        for dept_id, category in self.official_mapping.items():
            print(f"  - {dept_id}: {category}")

    def extract_categories_from_csv(self, file_path):
        """CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã‚«ãƒ†ã‚´ãƒªåã‚’æŠ½å‡º"""
        categories = set()
        try:
            # è¤‡æ•°ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’è©¦ã™
            encodings = ['utf-8', 'utf-8-sig', 'shift_jis', 'cp932']
            df = None
            
            for encoding in encodings:
                try:
                    df = pd.read_csv(file_path, encoding=encoding)
                    break
                except UnicodeDecodeError:
                    continue
            
            if df is None:
                print(f"âŒ ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚¨ãƒ©ãƒ¼: {file_path}")
                return categories
            
            # ã‚«ãƒ†ã‚´ãƒªåˆ—ã‚’æ¢ã™
            category_columns = ['ã‚«ãƒ†ã‚´ãƒª', 'category', 'Category', 'åˆ†é‡', 'éƒ¨é–€']
            category_column = None
            
            for col in category_columns:
                if col in df.columns:
                    category_column = col
                    break
            
            if category_column:
                # ã‚«ãƒ†ã‚´ãƒªåã‚’æŠ½å‡ºï¼ˆNaNå€¤ã‚’é™¤å¤–ï¼‰
                unique_categories = df[category_column].dropna().unique()
                categories = set(str(cat).strip() for cat in unique_categories if str(cat).strip())
            else:
                print(f"âš ï¸  ã‚«ãƒ†ã‚´ãƒªåˆ—ãŒè¦‹ã¤ã‹ã‚‰ãªã„: {file_path}")
                print(f"   åˆ©ç”¨å¯èƒ½ãªåˆ—: {list(df.columns)}")
                
        except Exception as e:
            print(f"âŒ CSVãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ {file_path}: {e}")
        
        return categories

    def analyze_csv_files(self):
        """å…¨CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†æ"""
        print("\nğŸ“Š CSVãƒ•ã‚¡ã‚¤ãƒ«åˆ†æé–‹å§‹...")
        
        csv_files = [f for f in os.listdir(self.data_dir) if f.endswith('.csv')]
        print(f"ç™ºè¦‹ã—ãŸCSVãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(csv_files)}")
        
        # å¹´åº¦ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æŠ½å‡º
        year_pattern = re.compile(r'(\d{4})')
        
        for csv_file in sorted(csv_files):
            file_path = os.path.join(self.data_dir, csv_file)
            print(f"\nğŸ” åˆ†æä¸­: {csv_file}")
            
            # å¹´åº¦ã‚’æŠ½å‡º
            year_match = year_pattern.search(csv_file)
            year = year_match.group(1) if year_match else "ä¸æ˜"
            
            # ã‚«ãƒ†ã‚´ãƒªã‚’æŠ½å‡º
            categories = self.extract_categories_from_csv(file_path)
            
            if categories:
                print(f"   ç™ºè¦‹ã‚«ãƒ†ã‚´ãƒªæ•°: {len(categories)}")
                for category in sorted(categories):
                    print(f"     - {category}")
                    
                    # å…¨ã‚«ãƒ†ã‚´ãƒªã«è¿½åŠ 
                    self.all_categories[csv_file].extend(categories)
                    
                    # å¹´åº¦åˆ¥åˆ†æã«è¿½åŠ 
                    if year not in self.year_analysis:
                        self.year_analysis[year] = defaultdict(list)
                    
                    for cat in categories:
                        if 'categories' not in self.year_analysis[year]:
                            self.year_analysis[year]['categories'] = []
                        if cat not in self.year_analysis[year]['categories']:
                            self.year_analysis[year]['categories'].append(cat)
                        
                        # è¡¨è¨˜æºã‚Œãƒã‚§ãƒƒã‚¯
                        normalized = self.normalize_category_name(cat)
                        self.category_variations[normalized].add(cat)
            else:
                print(f"   âš ï¸  ã‚«ãƒ†ã‚´ãƒªãŒè¦‹ã¤ã‹ã‚‰ãªã„")

    def normalize_category_name(self, category):
        """ã‚«ãƒ†ã‚´ãƒªåã‚’æ­£è¦åŒ–ï¼ˆè¡¨è¨˜æºã‚Œæ¤œå‡ºç”¨ï¼‰"""
        # ç©ºç™½ã€å¥èª­ç‚¹ã€ç‰¹æ®Šæ–‡å­—ã‚’é™¤å»ã—ã¦æ­£è¦åŒ–
        normalized = re.sub(r'[\s\u3000ã€ã€‚ï¼Œï¼ãƒ»]', '', str(category))
        normalized = normalized.replace('åŠã³', '')
        normalized = normalized.replace('ãŠã‚ˆã³', '')
        return normalized.lower()

    def check_consistency_with_official_mapping(self):
        """å…¬å¼ãƒãƒƒãƒ”ãƒ³ã‚°ã¨ã®æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯"""
        print("\nğŸ” å…¬å¼ãƒãƒƒãƒ”ãƒ³ã‚°ã¨ã®æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯...")
        
        # ç™ºè¦‹ã•ã‚ŒãŸã™ã¹ã¦ã®ã‚«ãƒ†ã‚´ãƒª
        all_found_categories = set()
        for categories_list in self.all_categories.values():
            all_found_categories.update(categories_list)
        
        print(f"ç™ºè¦‹ã•ã‚ŒãŸç·ã‚«ãƒ†ã‚´ãƒªæ•°: {len(all_found_categories)}")
        
        # å…¬å¼ã‚«ãƒ†ã‚´ãƒªã¨ã®æ¯”è¼ƒ
        official_set = self.official_categories
        found_set = all_found_categories
        
        # å…¬å¼ã«ã‚ã‚‹ãŒCSVã«ãªã„
        missing_in_csv = official_set - found_set
        if missing_in_csv:
            print(f"\nâŒ å…¬å¼ãƒãƒƒãƒ”ãƒ³ã‚°ã«ã‚ã‚‹ãŒCSVã«ãªã„ã‚«ãƒ†ã‚´ãƒª: {len(missing_in_csv)}")
            for cat in sorted(missing_in_csv):
                print(f"   - {cat}")
                self.inconsistencies.append({
                    'type': 'missing_in_csv',
                    'category': cat,
                    'description': 'å…¬å¼ãƒãƒƒãƒ”ãƒ³ã‚°ã«å®šç¾©ã•ã‚Œã¦ã„ã‚‹ãŒCSVãƒ‡ãƒ¼ã‚¿ã«å­˜åœ¨ã—ãªã„'
                })
        
        # CSVã«ã‚ã‚‹ãŒå…¬å¼ã«ãªã„
        extra_in_csv = found_set - official_set
        if extra_in_csv:
            print(f"\nâš ï¸  CSVã«ã‚ã‚‹ãŒå…¬å¼ãƒãƒƒãƒ”ãƒ³ã‚°ã«ãªã„ã‚«ãƒ†ã‚´ãƒª: {len(extra_in_csv)}")
            for cat in sorted(extra_in_csv):
                print(f"   - {cat}")
                self.inconsistencies.append({
                    'type': 'extra_in_csv',
                    'category': cat,
                    'description': 'CSVãƒ‡ãƒ¼ã‚¿ã«å­˜åœ¨ã™ã‚‹ãŒå…¬å¼ãƒãƒƒãƒ”ãƒ³ã‚°ã«å®šç¾©ã•ã‚Œã¦ã„ãªã„'
                })
        
        # å®Œå…¨ä¸€è‡´
        exact_matches = official_set & found_set
        print(f"\nâœ… å®Œå…¨ä¸€è‡´ã‚«ãƒ†ã‚´ãƒª: {len(exact_matches)}")
        for cat in sorted(exact_matches):
            print(f"   - {cat}")

    def detect_category_variations(self):
        """ã‚«ãƒ†ã‚´ãƒªåã®è¡¨è¨˜æºã‚Œæ¤œå‡º"""
        print("\nğŸ” è¡¨è¨˜æºã‚Œæ¤œå‡º...")
        
        variations_found = False
        for normalized, variations in self.category_variations.items():
            if len(variations) > 1:
                variations_found = True
                print(f"\nâš ï¸  è¡¨è¨˜æºã‚Œç™ºè¦‹: {normalized}")
                for var in sorted(variations):
                    print(f"   - {var}")
                
                self.inconsistencies.append({
                    'type': 'category_variation',
                    'normalized': normalized,
                    'variations': list(variations),
                    'description': f'åŒä¸€ã‚«ãƒ†ã‚´ãƒªã®è¡¨è¨˜æºã‚Œ: {len(variations)}ç¨®é¡'
                })
        
        if not variations_found:
            print("âœ… è¡¨è¨˜æºã‚Œã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")

    def analyze_yearly_consistency(self):
        """å¹´åº¦åˆ¥ä¸€è²«æ€§åˆ†æ"""
        print("\nğŸ” å¹´åº¦åˆ¥ä¸€è²«æ€§åˆ†æ...")
        
        # å¹´åº¦ã”ã¨ã®ã‚«ãƒ†ã‚´ãƒªã‚’æ¯”è¼ƒ
        all_years = sorted(self.year_analysis.keys())
        print(f"åˆ†æå¯¾è±¡å¹´åº¦: {all_years}")
        
        # å„ã‚«ãƒ†ã‚´ãƒªãŒå…¨å¹´åº¦ã§ä¸€è²«ã—ã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        all_categories_by_year = {}
        for year in all_years:
            if 'categories' in self.year_analysis[year]:
                all_categories_by_year[year] = set(self.year_analysis[year]['categories'])
        
        if len(all_categories_by_year) > 1:
            # å¹´åº¦é–“ã§ã®ã‚«ãƒ†ã‚´ãƒªå·®ç•°ã‚’ãƒã‚§ãƒƒã‚¯
            base_year = all_years[0]
            base_categories = all_categories_by_year.get(base_year, set())
            
            for year in all_years[1:]:
                year_categories = all_categories_by_year.get(year, set())
                
                # å¢—åŠ ã—ãŸã‚«ãƒ†ã‚´ãƒª
                added = year_categories - base_categories
                if added:
                    print(f"\nğŸ“ˆ {year}å¹´ã«è¿½åŠ ã•ã‚ŒãŸã‚«ãƒ†ã‚´ãƒª:")
                    for cat in sorted(added):
                        print(f"   + {cat}")
                
                # å‰Šé™¤ã•ã‚ŒãŸã‚«ãƒ†ã‚´ãƒª
                removed = base_categories - year_categories
                if removed:
                    print(f"\nğŸ“‰ {year}å¹´ã«å‰Šé™¤ã•ã‚ŒãŸã‚«ãƒ†ã‚´ãƒª:")
                    for cat in sorted(removed):
                        print(f"   - {cat}")
        else:
            print("å¹´åº¦ãƒ‡ãƒ¼ã‚¿ãŒä¸ååˆ†ã®ãŸã‚ã€å¹´åº¦åˆ¥æ¯”è¼ƒã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")

    def generate_detailed_report(self):
        """è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        print("\nğŸ“‹ è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ...")
        
        report = {
            'timestamp': datetime.now().isoformat(),
            'summary': {
                'total_csv_files': len(self.all_categories),
                'total_categories_found': len(set().union(*[cats for cats in self.all_categories.values()])),
                'official_categories_count': len(self.official_categories),
                'inconsistencies_count': len(self.inconsistencies)
            },
            'official_mapping': self.official_mapping,
            'found_categories_by_file': dict(self.all_categories),
            'category_variations': {k: list(v) for k, v in self.category_variations.items()},
            'yearly_analysis': dict(self.year_analysis),
            'inconsistencies': self.inconsistencies
        }
        
        # ãƒ¬ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        report_file = f"category_consistency_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜: {report_file}")
        
        return report

    def suggest_fixes(self):
        """ä¿®æ­£æ¡ˆã®æç¤º"""
        print("\nğŸ’¡ ä¿®æ­£æ¡ˆã®æç¤º...")
        
        fixes = []
        
        # è¡¨è¨˜æºã‚Œã®ä¿®æ­£æ¡ˆ
        for inconsistency in self.inconsistencies:
            if inconsistency['type'] == 'category_variation':
                variations = inconsistency['variations']
                # æœ€ã‚‚é•·ã„ï¼ˆè©³ç´°ãªï¼‰è¡¨è¨˜ã‚’æ¨™æº–ã¨ã™ã‚‹
                standard = max(variations, key=len)
                
                fix = {
                    'type': 'standardize_variations',
                    'standard_name': standard,
                    'variations_to_fix': [v for v in variations if v != standard],
                    'action': f'ã™ã¹ã¦ã®è¡¨è¨˜ã‚’ã€Œ{standard}ã€ã«çµ±ä¸€'
                }
                fixes.append(fix)
                print(f"ğŸ“ è¡¨è¨˜çµ±ä¸€æ¡ˆ: ã€Œ{standard}ã€ã«çµ±ä¸€")
                for var in fix['variations_to_fix']:
                    print(f"   {var} â†’ {standard}")
        
        # å…¬å¼ãƒãƒƒãƒ”ãƒ³ã‚°ã¨ã®ä¸æ•´åˆä¿®æ­£æ¡ˆ
        for inconsistency in self.inconsistencies:
            if inconsistency['type'] == 'extra_in_csv':
                category = inconsistency['category']
                
                # é¡ä¼¼ã®å…¬å¼ã‚«ãƒ†ã‚´ãƒªã‚’æ¤œç´¢
                best_match = self.find_best_match(category, self.official_categories)
                if best_match:
                    fix = {
                        'type': 'map_to_official',
                        'csv_category': category,
                        'suggested_official': best_match,
                        'action': f'ã€Œ{category}ã€ã‚’ã€Œ{best_match}ã€ã«ãƒãƒƒãƒ”ãƒ³ã‚°'
                    }
                    fixes.append(fix)
                    print(f"ğŸ“ ãƒãƒƒãƒ”ãƒ³ã‚°ææ¡ˆ: {category} â†’ {best_match}")
        
        return fixes

    def find_best_match(self, target, candidates):
        """æœ€é©ãªãƒãƒƒãƒãƒ³ã‚°ã‚’è¦‹ã¤ã‘ã‚‹"""
        target_normalized = self.normalize_category_name(target)
        
        best_match = None
        best_score = 0
        
        for candidate in candidates:
            candidate_normalized = self.normalize_category_name(candidate)
            
            # ç°¡å˜ãªé¡ä¼¼åº¦è¨ˆç®—ï¼ˆå…±é€šæ–‡å­—æ•°ï¼‰
            common_chars = len(set(target_normalized) & set(candidate_normalized))
            total_chars = len(set(target_normalized) | set(candidate_normalized))
            
            if total_chars > 0:
                score = common_chars / total_chars
                if score > best_score and score > 0.3:  # 30%ä»¥ä¸Šã®é¡ä¼¼åº¦
                    best_score = score
                    best_match = candidate
        
        return best_match

    def run_comprehensive_check(self):
        """åŒ…æ‹¬çš„ãƒã‚§ãƒƒã‚¯å®Ÿè¡Œ"""
        print("ğŸš€ RCCMè©¦é¨“å•é¡Œé›†ã‚¢ãƒ—ãƒª - å…¨12åˆ†é‡ã‚«ãƒ†ã‚´ãƒªåçµ±ä¸€æ€§æ¤œè¨¼")
        print("=" * 80)
        
        # 1. CSVãƒ•ã‚¡ã‚¤ãƒ«åˆ†æ
        self.analyze_csv_files()
        
        # 2. å…¬å¼ãƒãƒƒãƒ”ãƒ³ã‚°ã¨ã®æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
        self.check_consistency_with_official_mapping()
        
        # 3. è¡¨è¨˜æºã‚Œæ¤œå‡º
        self.detect_category_variations()
        
        # 4. å¹´åº¦åˆ¥ä¸€è²«æ€§åˆ†æ
        self.analyze_yearly_consistency()
        
        # 5. ä¿®æ­£æ¡ˆæç¤º
        fixes = self.suggest_fixes()
        
        # 6. è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        report = self.generate_detailed_report()
        
        # 7. ã‚µãƒãƒªãƒ¼è¡¨ç¤º
        print("\n" + "=" * 80)
        print("ğŸ“Š æ¤œè¨¼çµæœã‚µãƒãƒªãƒ¼")
        print("=" * 80)
        print(f"âœ… åˆ†ææ¸ˆã¿CSVãƒ•ã‚¡ã‚¤ãƒ«æ•°: {report['summary']['total_csv_files']}")
        print(f"âœ… ç™ºè¦‹ã‚«ãƒ†ã‚´ãƒªç·æ•°: {report['summary']['total_categories_found']}")
        print(f"âœ… å…¬å¼ã‚«ãƒ†ã‚´ãƒªæ•°: {report['summary']['official_categories_count']}")
        print(f"âš ï¸  ä¸æ•´åˆæ¤œå‡ºæ•°: {report['summary']['inconsistencies_count']}")
        print(f"ğŸ’¡ ä¿®æ­£æ¡ˆæ•°: {len(fixes)}")
        
        if report['summary']['inconsistencies_count'] == 0:
            print("\nğŸ‰ ãŠã‚ã§ã¨ã†ã”ã–ã„ã¾ã™ï¼ã‚«ãƒ†ã‚´ãƒªåã¯å®Œå…¨ã«çµ±ä¸€ã•ã‚Œã¦ã„ã¾ã™ï¼")
        else:
            print(f"\nâš ï¸  {report['summary']['inconsistencies_count']}ä»¶ã®ä¸æ•´åˆãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸã€‚ä¿®æ­£ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚")
        
        return report, fixes

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    data_dir = "data"
    
    if not os.path.exists(data_dir):
        print(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {data_dir}")
        return
    
    checker = ComprehensiveCategoryChecker(data_dir)
    report, fixes = checker.run_comprehensive_check()
    
    return report, fixes

if __name__ == "__main__":
    main()