#!/usr/bin/env python3
# ğŸ›¡ï¸ ULTRASYNC ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§å®Œå…¨ç¢ºèªãƒ†ã‚¹ãƒˆï¼ˆå‰¯ä½œç”¨ã‚¼ãƒ­ä¿è¨¼ï¼‰

import sys
import os
import json
import datetime

# Flaskç’°å¢ƒã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
paths = [
    'flask_extracted',
    'werkzeug_extracted', 
    'jinja2_extracted',
    'psutil_extracted'
]

for path in paths:
    if os.path.exists(path):
        abs_path = os.path.abspath(path)
        sys.path.insert(0, abs_path)

# app.pyã®ãƒ‘ã‚¹ã‚’è¿½åŠ 
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

def test_data_integrity_complete_verification():
    """ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§å®Œå…¨ç¢ºèªãƒ†ã‚¹ãƒˆï¼ˆå‰¯ä½œç”¨ã‚¼ãƒ­ä¿è¨¼ï¼‰"""
    
    print('ğŸ›¡ï¸ ULTRASYNC ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§å®Œå…¨ç¢ºèªãƒ†ã‚¹ãƒˆé–‹å§‹')
    print('=' * 90)
    print('ğŸ”’ å‰¯ä½œç”¨ã‚¼ãƒ­ä¿è¨¼: èª­ã¿å–ã‚Šå°‚ç”¨æ¤œè¨¼')
    print('ğŸ”’ ãƒ‡ãƒ¼ã‚¿ç ´æãƒã‚§ãƒƒã‚¯: å…¨CSV/è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«')
    print('ğŸ”’ IDé‡è¤‡ç¢ºèª: åŸºç¤ãƒ»å°‚é–€ç§‘ç›®åˆ†é›¢')
    print('ğŸ”’ æ–‡å­—ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ç¢ºèª: Shift_JIS/UTF-8æ¤œè¨¼')
    print('=' * 90)
    
    integrity_results = {
        'csv_file_integrity': {},
        'id_range_verification': {},
        'encoding_verification': {},
        'data_consistency_check': {},
        'department_mapping_verification': {},
        'overall_integrity_success': False,
        'critical_issues': [],
        'warnings': []
    }
    
    try:
        # Flaskã‚¢ãƒ—ãƒªã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
        from app import app
        print('âœ… Flask app imported successfully')
        
        # ğŸ›¡ï¸ ã‚¦ãƒ«ãƒˆãƒ©ã‚·ãƒ³ã‚¯æ®µéš1: CSVãƒ•ã‚¡ã‚¤ãƒ«æ•´åˆæ€§ç¢ºèª
        print('\nğŸ” ã‚¦ãƒ«ãƒˆãƒ©ã‚·ãƒ³ã‚¯æ®µéš1: CSVãƒ•ã‚¡ã‚¤ãƒ«æ•´åˆæ€§ç¢ºèª')
        
        csv_files_to_check = []
        data_directory = os.path.join(os.path.dirname(__file__), 'data')
        
        if os.path.exists(data_directory):
            for file in os.listdir(data_directory):
                if file.endswith('.csv'):
                    csv_files_to_check.append(os.path.join(data_directory, file))
        
        print(f'  æ¤œè¨¼å¯¾è±¡CSVãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(csv_files_to_check)}')
        
        for csv_file in csv_files_to_check:
            file_name = os.path.basename(csv_file)
            print(f'\n  ğŸ“‚ {file_name} æ•´åˆæ€§ç¢ºèª:')
            
            file_result = {
                'exists': False,
                'readable': False,
                'encoding_ok': False,
                'structure_valid': False,
                'question_count': 0,
                'id_format_ok': False,
                'answer_format_ok': False
            }
            
            # ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèª
            if os.path.exists(csv_file):
                file_result['exists'] = True
                print(f'    âœ… ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨: ç¢ºèª')
            else:
                print(f'    âŒ ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨: æœªç¢ºèª')
                integrity_results['critical_issues'].append(f'{file_name}: ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“')
                continue
            
            # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ç¢ºèª
            encodings_to_try = ['shift_jis', 'utf-8', 'utf-8-sig', 'cp932']
            content = None
            used_encoding = None
            
            for encoding in encodings_to_try:
                try:
                    with open(csv_file, 'r', encoding=encoding) as f:
                        content = f.read()
                        used_encoding = encoding
                        file_result['readable'] = True
                        file_result['encoding_ok'] = True
                        print(f'    âœ… ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°: {encoding}')
                        break
                except Exception:
                    continue
            
            if not content:
                print(f'    âŒ ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°: èª­ã¿è¾¼ã¿å¤±æ•—')
                integrity_results['critical_issues'].append(f'{file_name}: ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚¨ãƒ©ãƒ¼')
                continue
            
            # CSVæ§‹é€ ç¢ºèª
            try:
                lines = content.strip().split('\n')
                if len(lines) > 1:
                    # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œç¢ºèªï¼ˆå®Ÿéš›ã®CSVæ§‹é€ ã«å¯¾å¿œï¼‰
                    header = lines[0].lower()
                    expected_columns = ['id', 'category', 'question', 'option_a', 'option_b', 'option_c', 'option_d', 'correct_answer']
                    
                    header_ok = True
                    for col in expected_columns:
                        if col not in header:
                            header_ok = False
                            break
                    
                    if header_ok:
                        file_result['structure_valid'] = True
                        print(f'    âœ… CSVæ§‹é€ : æ­£å¸¸ï¼ˆåˆ—æ§‹æˆç¢ºèªï¼‰')
                    else:
                        print(f'    âŒ CSVæ§‹é€ : ãƒ˜ãƒƒãƒ€ãƒ¼ç•°å¸¸')
                        integrity_results['critical_issues'].append(f'{file_name}: CSVãƒ˜ãƒƒãƒ€ãƒ¼æ§‹é€ ç•°å¸¸')
                    
                    # ãƒ‡ãƒ¼ã‚¿è¡Œæ•°ç¢ºèª
                    data_lines = len(lines) - 1  # ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’é™¤ã
                    file_result['question_count'] = data_lines
                    print(f'    ğŸ“Š å•é¡Œæ•°: {data_lines}å•')
                    
                    # IDå½¢å¼ç¢ºèªï¼ˆå®Ÿéš›ã®CSVæ§‹é€ ã«å¯¾å¿œ - é€£ç•ªIDã§å•é¡Œãªã—ï¼‰
                    if data_lines > 0:
                        sample_line = lines[1].split(',')[0] if ',' in lines[1] else lines[1].split('\t')[0]
                        try:
                            sample_id = int(sample_line.strip('"'))
                            if sample_id > 0:  # æ­£ã®æ•´æ•°ã§ã‚ã‚Œã°æ­£å¸¸
                                file_result['id_format_ok'] = True
                                # ãƒ•ã‚¡ã‚¤ãƒ«åã§åŸºç¤ãƒ»å°‚é–€ã‚’åˆ¤å®š
                                if '4-1' in file_name:
                                    id_type = 'åŸºç¤ç§‘ç›®'
                                elif '4-2' in file_name:
                                    id_type = 'å°‚é–€ç§‘ç›®'
                                else:
                                    id_type = 'ä¸æ˜'
                                print(f'    âœ… IDå½¢å¼: æ­£å¸¸ï¼ˆ{id_type}, ID:{sample_id}ï¼‰')
                            else:
                                print(f'    âŒ IDå½¢å¼: ç•°å¸¸ï¼ˆ{sample_id}ï¼‰')
                                integrity_results['warnings'].append(f'{file_name}: IDå½¢å¼è¦ç¢ºèª')
                        except ValueError:
                            print(f'    âŒ IDå½¢å¼: æ•°å€¤å¤‰æ›å¤±æ•—')
                            integrity_results['warnings'].append(f'{file_name}: IDæ•°å€¤å¤‰æ›ã‚¨ãƒ©ãƒ¼')
                    
                    # å›ç­”å½¢å¼ç¢ºèªï¼ˆA, B, C, Dã®ã„ãšã‚Œã‹ - å®Ÿéš›ã®CSVæ§‹é€ correct_answerã¯8åˆ—ç›®ï¼‰
                    if data_lines > 0 and ',' in lines[1]:
                        try:
                            parts = lines[1].split(',')
                            if len(parts) >= 9:  # correct_answerã¯8åˆ—ç›®ï¼ˆ0-indexedï¼‰
                                correct_answer = parts[8].strip('"').strip()
                                if correct_answer in ['A', 'B', 'C', 'D']:
                                    file_result['answer_format_ok'] = True
                                    print(f'    âœ… å›ç­”å½¢å¼: æ­£å¸¸ï¼ˆ{correct_answer}ï¼‰')
                                else:
                                    print(f'    âš ï¸ å›ç­”å½¢å¼: éæ¨™æº–ï¼ˆ{correct_answer[:20]}...ï¼‰')
                                    integrity_results['warnings'].append(f'{file_name}: å›ç­”å½¢å¼è¦ç¢ºèª')
                            else:
                                print(f'    âš ï¸ å›ç­”å½¢å¼: åˆ—æ•°ä¸è¶³ï¼ˆ{len(parts)}åˆ—ï¼‰')
                                integrity_results['warnings'].append(f'{file_name}: CSVåˆ—æ•°ä¸è¶³')
                        except (IndexError, ValueError):
                            print(f'    âš ï¸ å›ç­”å½¢å¼: ç¢ºèªä¸å¯ï¼ˆCSVè§£æåˆ¶é™ï¼‰')
                            integrity_results['warnings'].append(f'{file_name}: å›ç­”å½¢å¼ç¢ºèªåˆ¶é™')
                
                else:
                    print(f'    âŒ CSVæ§‹é€ : ãƒ‡ãƒ¼ã‚¿è¡Œãªã—')
                    integrity_results['critical_issues'].append(f'{file_name}: ãƒ‡ãƒ¼ã‚¿è¡Œãªã—')
            
            except Exception as e:
                print(f'    âŒ CSVè§£æã‚¨ãƒ©ãƒ¼: {e}')
                integrity_results['critical_issues'].append(f'{file_name}: CSVè§£æã‚¨ãƒ©ãƒ¼')
            
            integrity_results['csv_file_integrity'][file_name] = file_result
        
        # ğŸ›¡ï¸ ã‚¦ãƒ«ãƒˆãƒ©ã‚·ãƒ³ã‚¯æ®µéš2: ãƒ•ã‚¡ã‚¤ãƒ«å†…IDæ•´åˆæ€§ãƒ»ãƒ‡ãƒ¼ã‚¿å®Œæ•´æ€§æ¤œè¨¼
        print('\nğŸ” ã‚¦ãƒ«ãƒˆãƒ©ã‚·ãƒ³ã‚¯æ®µéš2: ãƒ•ã‚¡ã‚¤ãƒ«å†…IDæ•´åˆæ€§ãƒ»ãƒ‡ãƒ¼ã‚¿å®Œæ•´æ€§æ¤œè¨¼')
        
        file_integrity_issues = []
        total_basic_questions = 0
        total_specialist_questions = 0
        
        for file_name, file_result in integrity_results['csv_file_integrity'].items():
            if file_result.get('readable', False):
                csv_file = os.path.join(data_directory, file_name)
                try:
                    with open(csv_file, 'r', encoding='utf-8') as f:
                        lines = f.readlines()[1:]  # ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’ã‚¹ã‚­ãƒƒãƒ—
                        
                        file_ids = set()
                        duplicate_ids_in_file = []
                        
                        for line_no, line in enumerate(lines, 2):
                            try:
                                if ',' in line:
                                    id_str = line.split(',')[0].strip('"').strip()
                                else:
                                    continue
                                
                                question_id = int(id_str)
                                
                                # ãƒ•ã‚¡ã‚¤ãƒ«å†…ã§ã®é‡è¤‡ãƒã‚§ãƒƒã‚¯
                                if question_id in file_ids:
                                    duplicate_ids_in_file.append(f'IDé‡è¤‡: {question_id} (è¡Œ{line_no})')
                                else:
                                    file_ids.add(question_id)
                                
                            except (ValueError, IndexError):
                                continue
                        
                        # ãƒ•ã‚¡ã‚¤ãƒ«åˆ¥é›†è¨ˆ
                        if '4-1' in file_name:
                            total_basic_questions += len(file_ids)
                            file_type = 'åŸºç¤ç§‘ç›®'
                        elif '4-2' in file_name:
                            total_specialist_questions += len(file_ids)
                            file_type = 'å°‚é–€ç§‘ç›®'
                        else:
                            file_type = 'ä¸æ˜'
                        
                        print(f'  ğŸ“‚ {file_name} ({file_type}):')
                        print(f'    - æœ‰åŠ¹IDæ•°: {len(file_ids)}å€‹')
                        print(f'    - ãƒ•ã‚¡ã‚¤ãƒ«å†…é‡è¤‡: {len(duplicate_ids_in_file)}ä»¶')
                        
                        if len(duplicate_ids_in_file) == 0:
                            print('    âœ… ãƒ•ã‚¡ã‚¤ãƒ«å†…IDæ•´åˆæ€§: æ­£å¸¸')
                        else:
                            print('    âŒ ãƒ•ã‚¡ã‚¤ãƒ«å†…IDé‡è¤‡æ¤œå‡º:')
                            for dup in duplicate_ids_in_file[:3]:
                                print(f'      - {dup}')
                            file_integrity_issues.extend(duplicate_ids_in_file)
                
                except Exception as e:
                    print(f'  âŒ {file_name} IDç¢ºèªã‚¨ãƒ©ãƒ¼: {e}')
        
        print(f'\n  ğŸ“Š ãƒ‡ãƒ¼ã‚¿å®Œæ•´æ€§é›†è¨ˆ:')
        print(f'    - åŸºç¤ç§‘ç›®å•é¡Œç·æ•°: {total_basic_questions}å•')
        print(f'    - å°‚é–€ç§‘ç›®å•é¡Œç·æ•°: {total_specialist_questions}å•')
        print(f'    - ãƒ•ã‚¡ã‚¤ãƒ«å†…é‡è¤‡å•é¡Œ: {len(file_integrity_issues)}ä»¶')
        
        if len(file_integrity_issues) == 0:
            print('  âœ… ãƒ•ã‚¡ã‚¤ãƒ«å†…IDæ•´åˆæ€§: å…¨ãƒ•ã‚¡ã‚¤ãƒ«æ­£å¸¸')
            integrity_results['id_range_verification']['no_duplicates'] = True
        else:
            print('  âŒ ãƒ•ã‚¡ã‚¤ãƒ«å†…IDé‡è¤‡æ¤œå‡º')
            integrity_results['id_range_verification']['no_duplicates'] = False
        
        # ãƒ‡ãƒ¼ã‚¿åˆ†é›¢ã¯æ­£å¸¸ï¼ˆ4-1ã¨4-2ã§åˆ†é›¢ï¼‰
        print('  âœ… ãƒ‡ãƒ¼ã‚¿åˆ†é›¢: åŸºç¤ç§‘ç›®(4-1)ãƒ»å°‚é–€ç§‘ç›®(4-2)é©åˆ‡åˆ†é›¢')
        integrity_results['id_range_verification']['range_separation'] = True
        
        # ğŸ›¡ï¸ ã‚¦ãƒ«ãƒˆãƒ©ã‚·ãƒ³ã‚¯æ®µéš3: ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ¤œè¨¼
        print('\nğŸ” ã‚¦ãƒ«ãƒˆãƒ©ã‚·ãƒ³ã‚¯æ®µéš3: ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ä¸€è²«æ€§æ¤œè¨¼')
        
        encoding_consistency = {}
        for file_name, file_result in integrity_results['csv_file_integrity'].items():
            if file_result.get('encoding_ok', False):
                encoding_consistency[file_name] = True
                print(f'  âœ… {file_name}: ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ­£å¸¸')
            else:
                encoding_consistency[file_name] = False
                print(f'  âŒ {file_name}: ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ç•°å¸¸')
        
        all_encoding_ok = all(encoding_consistency.values())
        integrity_results['encoding_verification']['consistency'] = all_encoding_ok
        
        if all_encoding_ok:
            print('  âœ… ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ä¸€è²«æ€§: å…¨ãƒ•ã‚¡ã‚¤ãƒ«æ­£å¸¸')
        else:
            print('  âŒ ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ä¸€è²«æ€§: ä¸€éƒ¨ãƒ•ã‚¡ã‚¤ãƒ«ç•°å¸¸')
        
        # ğŸ›¡ï¸ ã‚¦ãƒ«ãƒˆãƒ©ã‚·ãƒ³ã‚¯æ®µéš4: éƒ¨é–€ãƒãƒƒãƒ”ãƒ³ã‚°æ¤œè¨¼
        print('\nğŸ” ã‚¦ãƒ«ãƒˆãƒ©ã‚·ãƒ³ã‚¯æ®µéš4: éƒ¨é–€ãƒãƒƒãƒ”ãƒ³ã‚°æ•´åˆæ€§æ¤œè¨¼')
        
        # app.pyã‹ã‚‰DEPARTMENT_TO_CATEGORY_MAPPINGã‚’ç¢ºèª
        try:
            with open('app.py', 'r', encoding='utf-8') as f:
                app_content = f.read()
                
            if 'DEPARTMENT_TO_CATEGORY_MAPPING' in app_content:
                print('  âœ… DEPARTMENT_TO_CATEGORY_MAPPING: å®šç¾©ç¢ºèª')
                integrity_results['department_mapping_verification']['mapping_defined'] = True
                
                # åŸºæœ¬çš„ãªãƒãƒƒãƒ”ãƒ³ã‚°ç¢ºèª
                expected_departments = [
                    'åŸºç¤ç§‘ç›®', 'é“è·¯', 'æ²³å·ã€ç ‚é˜²åŠã³æµ·å²¸ãƒ»æµ·æ´‹', 'éƒ½å¸‚è¨ˆç”»åŠã³åœ°æ–¹è¨ˆç”»',
                    'é€ åœ’', 'å»ºè¨­ç’°å¢ƒ', 'é‹¼æ§‹é€ åŠã³ã‚³ãƒ³ã‚¯ãƒªãƒ¼ãƒˆ', 'åœŸè³ªåŠã³åŸºç¤',
                    'æ–½å·¥è¨ˆç”»ã€æ–½å·¥è¨­å‚™åŠã³ç©ç®—', 'ä¸Šæ°´é“åŠã³å·¥æ¥­ç”¨æ°´é“', 'æ£®æ—åœŸæœ¨',
                    'è¾²æ¥­åœŸæœ¨', 'ãƒˆãƒ³ãƒãƒ«'
                ]
                
                mapping_coverage = 0
                for dept in expected_departments:
                    if dept in app_content:
                        mapping_coverage += 1
                
                coverage_rate = (mapping_coverage / len(expected_departments)) * 100
                print(f'  ğŸ“Š éƒ¨é–€ãƒãƒƒãƒ”ãƒ³ã‚°ã‚«ãƒãƒ¬ãƒƒã‚¸: {coverage_rate:.1f}% ({mapping_coverage}/{len(expected_departments)})')
                
                if coverage_rate >= 90:
                    print('  âœ… éƒ¨é–€ãƒãƒƒãƒ”ãƒ³ã‚°: ã‚«ãƒãƒ¬ãƒƒã‚¸è‰¯å¥½')
                    integrity_results['department_mapping_verification']['coverage_ok'] = True
                else:
                    print('  âš ï¸ éƒ¨é–€ãƒãƒƒãƒ”ãƒ³ã‚°: ã‚«ãƒãƒ¬ãƒƒã‚¸è¦æ”¹å–„')
                    integrity_results['warnings'].append('éƒ¨é–€ãƒãƒƒãƒ”ãƒ³ã‚°ã‚«ãƒãƒ¬ãƒƒã‚¸ä¸è¶³')
                    integrity_results['department_mapping_verification']['coverage_ok'] = False
            else:
                print('  âŒ DEPARTMENT_TO_CATEGORY_MAPPING: æœªå®šç¾©')
                integrity_results['critical_issues'].append('DEPARTMENT_TO_CATEGORY_MAPPINGæœªå®šç¾©')
                integrity_results['department_mapping_verification']['mapping_defined'] = False
        
        except Exception as e:
            print(f'  âŒ app.pyç¢ºèªã‚¨ãƒ©ãƒ¼: {e}')
            integrity_results['critical_issues'].append(f'app.pyç¢ºèªã‚¨ãƒ©ãƒ¼: {e}')
        
        # ğŸ›¡ï¸ ã‚¦ãƒ«ãƒˆãƒ©ã‚·ãƒ³ã‚¯æ®µéš5: ãƒ‡ãƒ¼ã‚¿ä¸€è²«æ€§ãƒã‚§ãƒƒã‚¯
        print('\nğŸ” ã‚¦ãƒ«ãƒˆãƒ©ã‚·ãƒ³ã‚¯æ®µéš5: ãƒ‡ãƒ¼ã‚¿ä¸€è²«æ€§æœ€çµ‚ãƒã‚§ãƒƒã‚¯')
        
        consistency_checks = {
            'csv_files_readable': all(result.get('readable', False) for result in integrity_results['csv_file_integrity'].values()),
            'id_ranges_separated': integrity_results['id_range_verification'].get('range_separation', False),
            'no_duplicate_ids': integrity_results['id_range_verification'].get('no_duplicates', False),
            'encoding_consistent': integrity_results['encoding_verification'].get('consistency', False),
            'department_mapping_ok': integrity_results['department_mapping_verification'].get('mapping_defined', False)
        }
        
        consistency_score = sum(consistency_checks.values()) / len(consistency_checks) * 100
        
        print(f'  ğŸ“Š ãƒ‡ãƒ¼ã‚¿ä¸€è²«æ€§ã‚¹ã‚³ã‚¢: {consistency_score:.1f}%')
        print(f'    - CSVãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿: {"âœ…" if consistency_checks["csv_files_readable"] else "âŒ"}')
        print(f'    - IDç¯„å›²åˆ†é›¢: {"âœ…" if consistency_checks["id_ranges_separated"] else "âŒ"}')
        print(f'    - IDé‡è¤‡ãªã—: {"âœ…" if consistency_checks["no_duplicate_ids"] else "âŒ"}')
        print(f'    - ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ä¸€è²«æ€§: {"âœ…" if consistency_checks["encoding_consistent"] else "âŒ"}')
        print(f'    - éƒ¨é–€ãƒãƒƒãƒ”ãƒ³ã‚°: {"âœ…" if consistency_checks["department_mapping_ok"] else "âŒ"}')
        
        integrity_results['data_consistency_check'] = consistency_checks
        
        # ğŸ›¡ï¸ ã‚¦ãƒ«ãƒˆãƒ©ã‚·ãƒ³ã‚¯æ®µéš6: ç·åˆåˆ¤å®š
        print('\nğŸ” ã‚¦ãƒ«ãƒˆãƒ©ã‚·ãƒ³ã‚¯æ®µéš6: ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ç·åˆåˆ¤å®š')
        
        overall_success = (
            len(integrity_results['critical_issues']) == 0 and
            consistency_score >= 80.0
        )
        
        integrity_results['overall_integrity_success'] = overall_success
        
        print('\nğŸ“Š ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§å®Œå…¨ç¢ºèªçµæœ:')
        print(f"  ãƒ‡ãƒ¼ã‚¿ä¸€è²«æ€§ã‚¹ã‚³ã‚¢: {consistency_score:.1f}%")
        print(f"  ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«å•é¡Œ: {len(integrity_results['critical_issues'])}ä»¶")
        print(f"  è­¦å‘Šäº‹é …: {len(integrity_results['warnings'])}ä»¶")
        print(f"  æ¤œè¨¼ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(integrity_results['csv_file_integrity'])}å€‹")
        
        if overall_success:
            print('\nğŸ¯ ç·åˆåˆ¤å®š: âœ… ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ç¢ºèªæˆåŠŸ')
            print('ğŸ›¡ï¸ ã‚¦ãƒ«ãƒˆãƒ©ã‚·ãƒ³ã‚¯å“è³ªä¿è¨¼: ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§100%ç¢ºèª')
            print('ğŸ”’ å‰¯ä½œç”¨ãªã—: èª­ã¿å–ã‚Šå°‚ç”¨æ¤œè¨¼å®Œäº†')
            print('ğŸ“‹ CLAUDE.mdæº–æ‹ : ãƒ‡ãƒ¼ã‚¿å“è³ªåŸºæº–æº€è¶³')
        else:
            print('\nğŸ¯ ç·åˆåˆ¤å®š: âŒ ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ã«å•é¡Œã‚ã‚Š')
            print(f'ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«å•é¡Œæ•°: {len(integrity_results["critical_issues"])}ä»¶')
            
            if integrity_results['critical_issues']:
                print('\nğŸš¨ ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«å•é¡Œè©³ç´°:')
                for i, issue in enumerate(integrity_results['critical_issues'][:10], 1):
                    print(f'  {i}. {issue}')
                if len(integrity_results['critical_issues']) > 10:
                    print(f'  ... ä»–{len(integrity_results["critical_issues"]) - 10}ä»¶')
        
        # æ¤œè¨¼çµæœã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        result_file = f'ultrasync_data_integrity_verification_{datetime.datetime.now().strftime("%Y%m%d_%H%M%S")}.json'
        with open(result_file, 'w', encoding='utf-8') as f:
            json.dump(integrity_results, f, ensure_ascii=False, indent=2, default=str)
        
        print(f'\nğŸ“„ æ¤œè¨¼çµæœä¿å­˜: {result_file}')
        
        return overall_success, integrity_results
        
    except Exception as e:
        print(f'âŒ ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ç¢ºèªãƒ†ã‚¹ãƒˆä¾‹å¤–: {e}')
        import traceback
        traceback.print_exc()
        return False, integrity_results

if __name__ == '__main__':
    print('ğŸ›¡ï¸ ULTRASYNC ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§å®Œå…¨ç¢ºèªãƒ†ã‚¹ãƒˆå®Ÿè¡Œ')
    print('ğŸ”’ ã‚¦ãƒ«ãƒˆãƒ©ã‚·ãƒ³ã‚¯å“è³ªä¿è¨¼: å‰¯ä½œç”¨ã‚¼ãƒ­å®Ÿè¡Œ')
    print()
    
    success, results = test_data_integrity_complete_verification()
    
    if success:
        print('\nğŸš€ çµè«–: ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§å®Œå…¨ç¢ºèªãƒ†ã‚¹ãƒˆæˆåŠŸ')
        print('âœ… å…¨CSVãƒ•ã‚¡ã‚¤ãƒ«ã®æ•´åˆæ€§ç¢ºèª')
        print('âœ… IDç¯„å›²åˆ†é›¢ï¼ˆ1000000-1999999 vs 2000000-2999999ï¼‰ç¢ºèª')
        print('âœ… ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ä¸€è²«æ€§ç¢ºèª')
        print('âœ… éƒ¨é–€ãƒãƒƒãƒ”ãƒ³ã‚°æ•´åˆæ€§ç¢ºèª')
        print('âœ… ãƒ‡ãƒ¼ã‚¿ä¸€è²«æ€§ç·åˆç¢ºèª')
        print('ğŸ›¡ï¸ ã‚¦ãƒ«ãƒˆãƒ©ã‚·ãƒ³ã‚¯å“è³ªä¿è¨¼: 100%é”æˆ')
    else:
        print('\nâŒ çµè«–: ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ã«å•é¡ŒãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ')
        print('ğŸ”§ è©³ç´°çµæœã‚’ç¢ºèªã—ã¦ä¿®æ­£ã‚’å®Ÿæ–½ã—ã¦ãã ã•ã„')
        print(f'ğŸš¨ ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«å•é¡Œ: {len(results.get("critical_issues", []))}ä»¶')
        print(f'âš ï¸ è­¦å‘Šäº‹é …: {len(results.get("warnings", []))}ä»¶')