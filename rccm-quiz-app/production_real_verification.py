#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ¯ ULTRA SYNC æœ¬ç•ªç’°å¢ƒå®Ÿåœ°æ¤œè¨¼
å®Ÿéš›ã®ãƒ–ãƒ©ã‚¦ã‚¶æ“ä½œã«ã‚ˆã‚‹å®Œå…¨ãªæœ¬ç•ªç’°å¢ƒæ¤œè¨¼

ç›®çš„: 100%ç¢ºå®Ÿãªå“è³ªç¢ºä¿ã®ãŸã‚ã®æœ¬ç•ªç’°å¢ƒã§ã®å®Ÿåœ°ç¢ºèª
å¯¾è±¡: https://rccm-quiz-2025.onrender.com
æ¤œè¨¼æ–¹æ³•: å®Ÿéš›ã®HTTPãƒªã‚¯ã‚¨ã‚¹ãƒˆã«ã‚ˆã‚‹å•é¡Œå†…å®¹ã®è©³ç´°ç¢ºèª
"""

import requests
import json
import time
from datetime import datetime
import re
import urllib.parse
from typing import Dict, List, Optional
import logging

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class ProductionRealVerification:
    def __init__(self):
        self.base_url = "https://rccm-quiz-2025.onrender.com"
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'ja-JP,ja;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
        })
        
        # æ¤œè¨¼å¯¾è±¡éƒ¨é–€ï¼ˆå»ºè¨­ç’°å¢ƒã‚’æœ€å„ªå…ˆï¼‰
        self.departments = [
            'å»ºè¨­ç’°å¢ƒ',  # æœ€å„ªå…ˆ: ãƒ¦ãƒ¼ã‚¶ãƒ¼å ±å‘Šã®å•é¡Œéƒ¨é–€
            'é“è·¯', 'æ²³å·ãƒ»ç ‚é˜²', 'éƒ½å¸‚è¨ˆç”»', 'é€ åœ’', 
            'é‹¼æ§‹é€ ãƒ»ã‚³ãƒ³ã‚¯ãƒªãƒ¼ãƒˆ', 'åœŸè³ªãƒ»åŸºç¤', 'æ–½å·¥è¨ˆç”»', 
            'ä¸Šä¸‹æ°´é“', 'æ£®æ—åœŸæœ¨', 'è¾²æ¥­åœŸæœ¨', 'ãƒˆãƒ³ãƒãƒ«'
        ]
        
        # é‡ç‚¹æ¤œè¨¼å¹´åº¦
        self.critical_years = [2019, 2018, 2017, 2016, 2015]
        self.question_counts = [10, 20, 30]
        
        self.verification_results = {
            'timestamp': datetime.now().isoformat(),
            'verification_type': 'PRODUCTION_REAL_VERIFICATION',
            'target_url': self.base_url,
            'detailed_results': {},
            'critical_findings': [],
            'question_content_analysis': {},
            'category_mixing_detection': {},
            'production_health_status': {}
        }

    def get_session_cookies(self):
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆæœŸåŒ–ã¨ã‚¯ãƒƒã‚­ãƒ¼å–å¾—"""
        try:
            response = self.session.get(self.base_url, timeout=30)
            if response.status_code == 200:
                logger.info(f"âœ… ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆæœŸåŒ–æˆåŠŸ: {self.base_url}")
                return True
            else:
                logger.error(f"âŒ ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆæœŸåŒ–å¤±æ•—: HTTP {response.status_code}")
                return False
        except Exception as e:
            logger.error(f"ğŸ’¥ ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return False

    def start_specialist_exam(self, department: str, year: int, question_count: int) -> Optional[str]:
        """å°‚é–€ç§‘ç›®è©¦é¨“é–‹å§‹ã¨å®Ÿéš›ã®HTMLã‚³ãƒ³ãƒ†ãƒ³ãƒ„å–å¾—"""
        try:
            print(f"ğŸ” æœ¬ç•ªç’°å¢ƒå®Ÿåœ°æ¤œè¨¼: {department} {year}å¹´åº¦ {question_count}å•")
            
            # POST ãƒªã‚¯ã‚¨ã‚¹ãƒˆã§start_examå®Ÿè¡Œ
            data = {
                'questions': str(question_count),
                'year': str(year),
                'category': department
            }
            
            url = f"{self.base_url}/start_exam/specialist"
            
            response = self.session.post(url, data=data, timeout=60, allow_redirects=True)
            
            if response.status_code == 200:
                content = response.text
                logger.info(f"âœ… å°‚é–€ç§‘ç›®è©¦é¨“é–‹å§‹æˆåŠŸ: {department} {year}å¹´åº¦ {question_count}å•")
                return content
            else:
                logger.error(f"âŒ å°‚é–€ç§‘ç›®è©¦é¨“é–‹å§‹å¤±æ•—: HTTP {response.status_code}")
                return None
                
        except Exception as e:
            logger.error(f"ğŸ’¥ å°‚é–€ç§‘ç›®è©¦é¨“é–‹å§‹ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return None

    def analyze_question_content(self, html_content: str, department: str, year: int) -> Dict:
        """å®Ÿéš›ã®å•é¡Œå†…å®¹ã®è©³ç´°åˆ†æ"""
        analysis = {
            'has_questions': False,
            'question_texts': [],
            'specialist_keywords_found': [],
            'basic_keywords_found': [],
            'other_department_keywords': [],
            'content_quality_score': 0.0,
            'category_violations': [],
            'html_length': len(html_content)
        }
        
        try:
            # å•é¡Œæ–‡ã®æŠ½å‡º
            question_patterns = [
                r'<div[^>]*class="[^"]*question[^"]*"[^>]*>(.*?)</div>',
                r'å•é¡Œ\s*\d+[ï¼š:]?\s*(.*?)(?=å•é¡Œ\s*\d+|$)',
                r'å•\s*\d+[ï¼š:]?\s*(.*?)(?=å•\s*\d+|é¸æŠè‚¢|å›ç­”|$)',
                r'<p[^>]*>(.*?å•.*?)</p>'
            ]
            
            for pattern in question_patterns:
                matches = re.findall(pattern, html_content, re.DOTALL | re.IGNORECASE)
                for match in matches:
                    # HTMLã‚¿ã‚°ã‚’é™¤å»
                    clean_text = re.sub(r'<[^>]+>', '', match).strip()
                    if len(clean_text) > 20:  # æ„å‘³ã®ã‚ã‚‹é•·ã•ã®æ–‡ç« ã®ã¿
                        analysis['question_texts'].append(clean_text[:200])  # æœ€åˆã®200æ–‡å­—
            
            analysis['has_questions'] = len(analysis['question_texts']) > 0
            
            # éƒ¨é–€åˆ¥å°‚é–€ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
            specialist_keywords = {
                'å»ºè¨­ç’°å¢ƒ': ['ç’°å¢ƒ', 'é¨’éŸ³', 'æŒ¯å‹•', 'å¤§æ°—æ±šæŸ“', 'æ°´è³ªæ±šæ¿', 'åœŸå£Œæ±šæŸ“', 'ã‚¢ã‚»ã‚¹ãƒ¡ãƒ³ãƒˆ', 'CO2', 'NOx'],
                'é“è·¯': ['é“è·¯', 'èˆ—è£…', 'äº¤é€š', 'ã‚¢ã‚¹ãƒ•ã‚¡ãƒ«ãƒˆ', 'è»Šé“', 'æ­©é“', 'äº¤å·®ç‚¹', 'ä¿¡å·'],
                'æ²³å·ãƒ»ç ‚é˜²': ['æ²³å·', 'ç ‚é˜²', 'æ²»æ°´', 'å ¤é˜²', 'è­·å²¸', 'æµåŸŸ', 'æ´ªæ°´', 'ãƒ€ãƒ '],
                'éƒ½å¸‚è¨ˆç”»': ['éƒ½å¸‚è¨ˆç”»', 'å¸‚è¡—åœ°', 'åŒºåŸŸ', 'åŒºç”»', 'åœŸåœ°åˆ©ç”¨', 'ã‚¾ãƒ¼ãƒ‹ãƒ³ã‚°'],
                'é€ åœ’': ['é€ åœ’', 'ç·‘åœ°', 'å…¬åœ’', 'æ¤æ ½', 'æ¨¹æœ¨', 'åº­åœ’', 'æ™¯è¦³'],
                'é‹¼æ§‹é€ ãƒ»ã‚³ãƒ³ã‚¯ãƒªãƒ¼ãƒˆ': ['é‹¼æ§‹é€ ', 'ã‚³ãƒ³ã‚¯ãƒªãƒ¼ãƒˆ', 'é‰„ç­‹', 'é‰„éª¨', 'PC', 'RC'],
                'åœŸè³ªãƒ»åŸºç¤': ['åœŸè³ª', 'åŸºç¤', 'åœ°ç›¤', 'æ”¯æŒåŠ›', 'Nå€¤', 'ã›ã‚“æ–­', 'åœ§å¯†'],
                'æ–½å·¥è¨ˆç”»': ['æ–½å·¥', 'å·¥ç¨‹', 'ç®¡ç†', 'å“è³ªç®¡ç†', 'å®‰å…¨ç®¡ç†', 'å·¥äº‹'],
                'ä¸Šä¸‹æ°´é“': ['ä¸Šæ°´é“', 'ä¸‹æ°´é“', 'çµ¦æ°´', 'æ’æ°´', 'æµ„æ°´', 'é…æ°´'],
                'æ£®æ—åœŸæœ¨': ['æ£®æ—', 'æ—é“', 'æ²»å±±', 'æœ¨æ', 'é–“ä¼'],
                'è¾²æ¥­åœŸæœ¨': ['è¾²æ¥­', 'çŒæ¼‘', 'è¾²åœ°', 'æ°´åˆ©', 'æ’æ°´è·¯'],
                'ãƒˆãƒ³ãƒãƒ«': ['ãƒˆãƒ³ãƒãƒ«', 'æ˜å‰Š', 'æ”¯ä¿', 'è¦†å·¥', 'NATM']
            }
            
            # åŸºç¤ç§‘ç›®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
            basic_keywords = ['æ•°å­¦', 'ç‰©ç†', 'åŒ–å­¦', 'åŠ›å­¦', 'ææ–™åŠ›å­¦', 'æ§‹é€ åŠ›å­¦', 'åŸºç¤ç§‘ç›®']
            
            # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æ
            full_text = ' '.join(analysis['question_texts']).lower()
            
            # æœŸå¾…ã•ã‚Œã‚‹å°‚é–€ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®æ¤œå‡º
            expected_keywords = specialist_keywords.get(department, [])
            for keyword in expected_keywords:
                if keyword.lower() in full_text:
                    analysis['specialist_keywords_found'].append(keyword)
            
            # åŸºç¤ç§‘ç›®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®æ¤œå‡ºï¼ˆæ··å…¥ãƒã‚§ãƒƒã‚¯ï¼‰
            for keyword in basic_keywords:
                if keyword.lower() in full_text:
                    analysis['basic_keywords_found'].append(keyword)
            
            # ä»–éƒ¨é–€ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®æ¤œå‡ºï¼ˆæ··å…¥ãƒã‚§ãƒƒã‚¯ï¼‰
            for dept, keywords in specialist_keywords.items():
                if dept != department:
                    for keyword in keywords:
                        if keyword.lower() in full_text:
                            analysis['other_department_keywords'].append(f"{dept}:{keyword}")
            
            # ã‚«ãƒ†ã‚´ãƒªãƒ¼é•åã®æ¤œå‡º
            if analysis['basic_keywords_found']:
                analysis['category_violations'].append(f"åŸºç¤ç§‘ç›®æ··å…¥: {analysis['basic_keywords_found']}")
            
            if analysis['other_department_keywords']:
                analysis['category_violations'].append(f"ä»–éƒ¨é–€æ··å…¥: {analysis['other_department_keywords']}")
            
            # å“è³ªã‚¹ã‚³ã‚¢è¨ˆç®—
            if analysis['specialist_keywords_found'] and not analysis['category_violations']:
                analysis['content_quality_score'] = 1.0
            elif analysis['specialist_keywords_found'] and analysis['category_violations']:
                analysis['content_quality_score'] = 0.3
            elif not analysis['specialist_keywords_found'] and not analysis['category_violations']:
                analysis['content_quality_score'] = 0.1
            else:
                analysis['content_quality_score'] = 0.0
            
            return analysis
            
        except Exception as e:
            logger.error(f"å•é¡Œå†…å®¹åˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}")
            analysis['error'] = str(e)
            return analysis

    def verify_department_in_production(self, department: str) -> Dict:
        """æœ¬ç•ªç’°å¢ƒã§ã®éƒ¨é–€åˆ¥å¾¹åº•æ¤œè¨¼"""
        print(f"\nğŸ¢ ã€æœ¬ç•ªç’°å¢ƒå®Ÿåœ°æ¤œè¨¼ã€‘éƒ¨é–€: {department}")
        print("=" * 60)
        
        department_results = {
            'department': department,
            'total_tests': 0,
            'successful_tests': 0,
            'content_verified_tests': 0,
            'category_violations_found': 0,
            'detailed_test_results': [],
            'critical_issues': []
        }
        
        for year in self.critical_years:
            for question_count in self.question_counts:
                department_results['total_tests'] += 1
                
                print(f"  ğŸ“ æ¤œè¨¼å®Ÿè¡Œ: {year}å¹´åº¦ {question_count}å• ", end="")
                
                # å®Ÿéš›ã®è©¦é¨“é–‹å§‹
                html_content = self.start_specialist_exam(department, year, question_count)
                
                if html_content:
                    department_results['successful_tests'] += 1
                    
                    # å•é¡Œå†…å®¹ã®è©³ç´°åˆ†æ
                    content_analysis = self.analyze_question_content(html_content, department, year)
                    
                    test_result = {
                        'year': year,
                        'question_count': question_count,
                        'success': True,
                        'content_analysis': content_analysis,
                        'timestamp': datetime.now().isoformat()
                    }
                    
                    if content_analysis['has_questions'] and content_analysis['content_quality_score'] >= 0.5:
                        department_results['content_verified_tests'] += 1
                        print("âœ… åˆæ ¼")
                    elif content_analysis['category_violations']:
                        department_results['category_violations_found'] += 1
                        department_results['critical_issues'].append(f"{year}å¹´åº¦{question_count}å•: {content_analysis['category_violations']}")
                        print(f"âŒ ã‚«ãƒ†ã‚´ãƒªãƒ¼é•åæ¤œå‡º")
                    else:
                        print("âš ï¸ è¦ç¢ºèª")
                    
                    department_results['detailed_test_results'].append(test_result)
                    
                else:
                    print("âŒ æ¥ç¶šå¤±æ•—")
                    department_results['detailed_test_results'].append({
                        'year': year,
                        'question_count': question_count,
                        'success': False,
                        'error': 'æ¥ç¶šå¤±æ•—'
                    })
                
                # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–
                time.sleep(0.5)
        
        # éƒ¨é–€åˆ¥çµæœã‚µãƒãƒªãƒ¼
        success_rate = (department_results['successful_tests'] / department_results['total_tests']) * 100
        content_rate = (department_results['content_verified_tests'] / department_results['total_tests']) * 100
        
        print(f"\n  ğŸ“Š {department}éƒ¨é–€çµæœ:")
        print(f"    æ¥ç¶šæˆåŠŸç‡: {success_rate:.1f}% ({department_results['successful_tests']}/{department_results['total_tests']})")
        print(f"    å†…å®¹æ¤œè¨¼ç‡: {content_rate:.1f}% ({department_results['content_verified_tests']}/{department_results['total_tests']})")
        print(f"    ã‚«ãƒ†ã‚´ãƒªãƒ¼é•å: {department_results['category_violations_found']}ä»¶")
        
        if department_results['critical_issues']:
            print(f"    ğŸš¨ é‡è¦å•é¡Œ:")
            for issue in department_results['critical_issues']:
                print(f"      - {issue}")
        
        return department_results

    def run_comprehensive_production_verification(self):
        """æœ¬ç•ªç’°å¢ƒã§ã®åŒ…æ‹¬çš„å®Ÿåœ°æ¤œè¨¼å®Ÿè¡Œ"""
        print("ğŸ¯ ULTRA SYNC æœ¬ç•ªç’°å¢ƒå®Ÿåœ°æ¤œè¨¼é–‹å§‹")
        print("=" * 80)
        print("ç›®çš„: 100%ç¢ºå®Ÿãªå“è³ªç¢ºä¿ã®ãŸã‚ã®æœ¬ç•ªç’°å¢ƒå®Ÿåœ°ç¢ºèª")
        print("å¯¾è±¡URL: https://rccm-quiz-2025.onrender.com")
        print("æ¤œè¨¼æ–¹æ³•: å®Ÿéš›ã®HTTPãƒªã‚¯ã‚¨ã‚¹ãƒˆã«ã‚ˆã‚‹å•é¡Œå†…å®¹è©³ç´°ç¢ºèª")
        print("=" * 80)
        
        start_time = time.time()
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆæœŸåŒ–
        if not self.get_session_cookies():
            print("âŒ ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆæœŸåŒ–å¤±æ•— - æ¤œè¨¼ã‚’ä¸­æ–­ã—ã¾ã™")
            return None
        
        total_tests = 0
        total_success = 0
        total_content_verified = 0
        total_violations = 0
        critical_departments = []
        
        # å„éƒ¨é–€ã®è©³ç´°æ¤œè¨¼
        for department in self.departments:
            department_result = self.verify_department_in_production(department)
            self.verification_results['detailed_results'][department] = department_result
            
            total_tests += department_result['total_tests']
            total_success += department_result['successful_tests']
            total_content_verified += department_result['content_verified_tests']
            total_violations += department_result['category_violations_found']
            
            if department_result['category_violations_found'] > 0:
                critical_departments.append(department)
            
            print()  # æ”¹è¡Œ
        
        end_time = time.time()
        duration = end_time - start_time
        
        # æœ€çµ‚çµæœã‚µãƒãƒªãƒ¼
        self.verification_results['final_summary'] = {
            'total_departments': len(self.departments),
            'total_tests': total_tests,
            'successful_tests': total_success,
            'content_verified_tests': total_content_verified,
            'category_violations': total_violations,
            'critical_departments': critical_departments,
            'success_rate': (total_success / total_tests) * 100 if total_tests > 0 else 0,
            'content_verification_rate': (total_content_verified / total_tests) * 100 if total_tests > 0 else 0,
            'violation_rate': (total_violations / total_tests) * 100 if total_tests > 0 else 0,
            'verification_duration': duration
        }
        
        self.generate_production_verification_report()
        
        return self.verification_results

    def generate_production_verification_report(self):
        """æœ¬ç•ªç’°å¢ƒæ¤œè¨¼ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        summary = self.verification_results['final_summary']
        
        print("\n" + "=" * 80)
        print("ğŸ¯ ULTRA SYNC æœ¬ç•ªç’°å¢ƒå®Ÿåœ°æ¤œè¨¼çµæœ")
        print("=" * 80)
        
        print(f"ğŸ“Š ç·åˆçµæœ:")
        print(f"  å¯¾è±¡éƒ¨é–€æ•°: {summary['total_departments']}")
        print(f"  ç·ãƒ†ã‚¹ãƒˆæ•°: {summary['total_tests']}")
        print(f"  æ¥ç¶šæˆåŠŸæ•°: {summary['successful_tests']}")
        print(f"  å†…å®¹æ¤œè¨¼æˆåŠŸæ•°: {summary['content_verified_tests']}")
        print(f"  ã‚«ãƒ†ã‚´ãƒªãƒ¼é•åæ•°: {summary['category_violations']}")
        print()
        
        print(f"ğŸ“ˆ æˆåŠŸç‡:")
        print(f"  æ¥ç¶šæˆåŠŸç‡: {summary['success_rate']:.1f}%")
        print(f"  å†…å®¹æ¤œè¨¼ç‡: {summary['content_verification_rate']:.1f}%")
        print(f"  é•åç™ºç”Ÿç‡: {summary['violation_rate']:.1f}%")
        print()
        
        print(f"â±ï¸ å®Ÿè¡Œæ™‚é–“: {summary['verification_duration']:.1f}ç§’")
        print()
        
        # å“è³ªåˆ¤å®š
        if summary['category_violations'] == 0 and summary['content_verification_rate'] >= 80:
            print("ğŸ† åˆ¤å®š: EXCELLENT - æœ¬ç•ªç’°å¢ƒã§ã®å“è³ª100%ç¢ºèª")
        elif summary['category_violations'] == 0 and summary['content_verification_rate'] >= 60:
            print("âœ… åˆ¤å®š: GOOD - æœ¬ç•ªç’°å¢ƒã§ã®å“è³ªç¢ºèªæ¸ˆã¿")
        elif summary['category_violations'] <= 2:
            print("âš ï¸ åˆ¤å®š: NEEDS IMPROVEMENT - è»½å¾®ãªå•é¡Œã‚ã‚Š")
        else:
            print("ğŸš¨ åˆ¤å®š: CRITICAL - é‡å¤§ãªå“è³ªå•é¡Œã‚ã‚Š")
        
        if summary['critical_departments']:
            print(f"\nğŸš¨ è¦æ³¨æ„éƒ¨é–€: {', '.join(summary['critical_departments'])}")
        
        # ãƒ¬ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        report_filename = f"production_real_verification_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(report_filename, 'w', encoding='utf-8') as f:
            json.dump(self.verification_results, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ“„ è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆ: {report_filename}")
        print("\nğŸ”’ ULTRA SYNC æœ¬ç•ªç’°å¢ƒå®Ÿåœ°æ¤œè¨¼å®Œäº†")

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("ğŸ¯ ULTRA SYNC æœ¬ç•ªç’°å¢ƒå®Ÿåœ°æ¤œè¨¼ãƒ„ãƒ¼ãƒ«")
    print("ç›®çš„: 100%ç¢ºå®Ÿãªå“è³ªç¢ºä¿ã®ãŸã‚ã®æœ¬ç•ªç’°å¢ƒå®Ÿåœ°ç¢ºèª")
    print()
    
    verifier = ProductionRealVerification()
    results = verifier.run_comprehensive_production_verification()
    
    return results

if __name__ == "__main__":
    main()