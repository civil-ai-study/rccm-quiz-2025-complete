#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å…¨13éƒ¨é–€ã®åˆ†é‡æ··åœ¨å•é¡Œã®åŒ…æ‹¬çš„åˆ†æã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆçµ¶å¯¾ã«å˜˜ã‚’ã¤ã‹ãªã„ï¼‰
- å…¨éƒ¨é–€ã§ã®åˆ†é‡æ··åœ¨ã®å¯èƒ½æ€§ã‚’å¾¹åº•èª¿æŸ»
- å®Ÿéš›ã®ã‚¢ãƒ—ãƒªãƒ•ãƒ­ãƒ¼ã‚’å®Œå…¨å†ç¾
- å„éƒ¨é–€ã®å•é¡Œå–å¾—ãƒ­ã‚¸ãƒƒã‚¯ã®è©³ç´°åˆ†æ
"""

import sys
import os
import csv
import random
import json
import logging
from datetime import datetime

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def comprehensive_field_mixing_analysis():
    """å…¨13éƒ¨é–€ã®åˆ†é‡æ··åœ¨å•é¡Œã‚’åŒ…æ‹¬çš„ã«åˆ†æ"""
    
    print("=" * 100)
    print("ğŸš¨ å…¨13éƒ¨é–€ åˆ†é‡æ··åœ¨å•é¡Œ åŒ…æ‹¬çš„åˆ†æï¼ˆçµ¶å¯¾ã«å˜˜ã‚’ã¤ã‹ãªã„ï¼‰")
    print("=" * 100)
    
    # å…¨13éƒ¨é–€ã®ãƒªã‚¹ãƒˆï¼ˆåŸºç¤ç§‘ç›®ã‚’å«ã‚€ï¼‰
    all_departments = [
        'åŸºç¤ç§‘ç›®',     # åŸºç¤ç§‘ç›®ï¼ˆå…±é€šï¼‰
        'é“è·¯',         # é“è·¯éƒ¨é–€
        'æ²³å·ãƒ»ç ‚é˜²',   # æ²³å·ãƒ»ç ‚é˜²éƒ¨é–€  
        'éƒ½å¸‚è¨ˆç”»',     # éƒ½å¸‚è¨ˆç”»éƒ¨é–€
        'é€ åœ’',         # é€ åœ’éƒ¨é–€
        'å»ºè¨­ç’°å¢ƒ',     # å»ºè¨­ç’°å¢ƒéƒ¨é–€
        'é‹¼æ§‹é€ ãƒ»ã‚³ãƒ³ã‚¯ãƒªãƒ¼ãƒˆ', # é‹¼æ§‹é€ ãƒ»ã‚³ãƒ³ã‚¯ãƒªãƒ¼ãƒˆéƒ¨é–€
        'åœŸè³ªãƒ»åŸºç¤',   # åœŸè³ªãƒ»åŸºç¤éƒ¨é–€
        'æ–½å·¥è¨ˆç”»',     # æ–½å·¥è¨ˆç”»éƒ¨é–€
        'ä¸Šä¸‹æ°´é“',     # ä¸Šä¸‹æ°´é“éƒ¨é–€
        'æ£®æ—åœŸæœ¨',     # æ£®æ—åœŸæœ¨éƒ¨é–€
        'è¾²æ¥­åœŸæœ¨',     # è¾²æ¥­åœŸæœ¨éƒ¨é–€ï¼ˆæ—¢ã«å•é¡Œç™ºè¦‹æ¸ˆã¿ï¼‰
        'ãƒˆãƒ³ãƒãƒ«'      # ãƒˆãƒ³ãƒãƒ«éƒ¨é–€
    ]
    
    # app.pyã®CSV_JAPANESE_CATEGORIESãƒãƒƒãƒ”ãƒ³ã‚°ã‚’å®Œå…¨å†ç¾
    CSV_JAPANESE_CATEGORIES = {
        "åŸºç¤ç§‘ç›®": "å…±é€š",
        "é“è·¯": "é“è·¯",
        "æ²³å·ãƒ»ç ‚é˜²": "æ²³å·ã€ç ‚é˜²åŠã³æµ·å²¸ãƒ»æµ·æ´‹", 
        "éƒ½å¸‚è¨ˆç”»": "éƒ½å¸‚è¨ˆç”»åŠã³åœ°æ–¹è¨ˆç”»",
        "é€ åœ’": "é€ åœ’",
        "å»ºè¨­ç’°å¢ƒ": "å»ºè¨­ç’°å¢ƒ", 
        "é‹¼æ§‹é€ ãƒ»ã‚³ãƒ³ã‚¯ãƒªãƒ¼ãƒˆ": "é‹¼æ§‹é€ åŠã³ã‚³ãƒ³ã‚¯ãƒªãƒ¼ãƒˆ",
        "åœŸè³ªãƒ»åŸºç¤": "åœŸè³ªåŠã³åŸºç¤",
        "æ–½å·¥è¨ˆç”»": "æ–½å·¥è¨ˆç”»ã€æ–½å·¥è¨­å‚™åŠã³ç©ç®—",
        "ä¸Šä¸‹æ°´é“": "ä¸Šæ°´é“åŠã³å·¥æ¥­ç”¨æ°´é“",
        "æ£®æ—åœŸæœ¨": "æ£®æ—åœŸæœ¨", 
        "è¾²æ¥­åœŸæœ¨": "è¾²æ¥­åœŸæœ¨",
        "ãƒˆãƒ³ãƒãƒ«": "ãƒˆãƒ³ãƒãƒ«"
    }
    
    def load_questions_for_analysis(csv_path):
        """å•é¡Œãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æç”¨ã«èª­ã¿è¾¼ã¿"""
        questions = []
        if not os.path.exists(csv_path):
            return questions
            
        try:
            with open(csv_path, 'r', encoding='utf-8') as f:
                reader = csv.DictReader(f)
                for row in reader:
                    questions.append(dict(row))
        except Exception as e:
            logger.warning(f"ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿å¤±æ•—: {csv_path} - {e}")
        
        return questions
    
    def analyze_category_consistency(department_name):
        """éƒ¨é–€ã®ã‚«ãƒ†ã‚´ãƒªä¸€è²«æ€§ã‚’è©³ç´°åˆ†æ"""
        print(f"\n{'='*80}")
        print(f"ğŸ“Š {department_name}éƒ¨é–€ åˆ†é‡æ··åœ¨åˆ†æ")
        print('='*80)
        
        if department_name not in CSV_JAPANESE_CATEGORIES:
            print(f"âŒ ERROR: æœªå¯¾å¿œéƒ¨é–€ - {department_name}")
            return {'error': f'æœªå¯¾å¿œéƒ¨é–€: {department_name}'}
        
        expected_category = CSV_JAPANESE_CATEGORIES[department_name]
        print(f"æœŸå¾…ã‚«ãƒ†ã‚´ãƒª: '{expected_category}'")
        
        # åŸºç¤ç§‘ç›®ã®ç‰¹åˆ¥å‡¦ç†
        if expected_category == "å…±é€š":
            print("âš ï¸ åŸºç¤ç§‘ç›®ã¯åˆ¥å‡¦ç†ï¼ˆ4-1ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ï¼‰")
            # åŸºç¤ç§‘ç›®ç”¨ã®ãƒ‡ãƒ¼ã‚¿åˆ†æã¯åˆ¥é€”å®Ÿè£…ãŒå¿…è¦
            return {
                'department': department_name,
                'expected_category': expected_category,
                'note': 'åŸºç¤ç§‘ç›®ã¯å°‚é–€ç§‘ç›®ã¨ã¯ç•°ãªã‚‹ãƒ‡ãƒ¼ã‚¿æ§‹é€ ',
                'mixing_detected': False,
                'requires_separate_analysis': True
            }
        
        # å°‚é–€ç§‘ç›®ï¼ˆ4-2ï¼‰ã®åˆ†æ
        VALID_YEARS = [2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019]
        
        category_analysis = {
            'department': department_name,
            'expected_category': expected_category,
            'total_questions_found': 0,
            'category_breakdown': {},
            'mixing_detected': False,
            'mixing_details': [],
            'year_analysis': {}
        }
        
        all_categories_found = set()
        
        # å¹´åº¦åˆ¥ãƒ‡ãƒ¼ã‚¿åˆ†æ
        for year in VALID_YEARS:
            csv_path = f'rccm-quiz-app/data/4-2_{year}.csv'
            print(f"\nå¹´åº¦ãƒ•ã‚¡ã‚¤ãƒ«åˆ†æ: {year}")
            
            if not os.path.exists(csv_path):
                print(f"  ãƒ•ã‚¡ã‚¤ãƒ«ä¸å­˜åœ¨: {csv_path}")
                continue
            
            year_data = load_questions_for_analysis(csv_path)
            if not year_data:
                print(f"  ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å¤±æ•—: {csv_path}")
                continue
            
            print(f"  èª­ã¿è¾¼ã¿æˆåŠŸ: {len(year_data)}å•")
            
            # ã“ã®å¹´åº¦ã§ã®æœŸå¾…ã‚«ãƒ†ã‚´ãƒªã®å•é¡Œæ•°
            expected_count = 0
            year_categories = {}
            
            for row in year_data:
                row_category = row.get('category', '').strip()
                
                # ã‚«ãƒ†ã‚´ãƒªçµ±è¨ˆ
                if row_category not in year_categories:
                    year_categories[row_category] = 0
                year_categories[row_category] += 1
                
                all_categories_found.add(row_category)
                
                # æœŸå¾…ã‚«ãƒ†ã‚´ãƒªã¨ã®ä¸€è‡´ç¢ºèª
                if row_category == expected_category:
                    expected_count += 1
            
            category_analysis['year_analysis'][year] = {
                'total_questions': len(year_data),
                'expected_category_count': expected_count,
                'all_categories': year_categories
            }
            
            print(f"  æœŸå¾…ã‚«ãƒ†ã‚´ãƒª '{expected_category}': {expected_count}å•")
            print(f"  ç™ºè¦‹ã•ã‚ŒãŸå…¨ã‚«ãƒ†ã‚´ãƒª: {list(year_categories.keys())}")
            
            # æ··åœ¨ãƒã‚§ãƒƒã‚¯
            if expected_count > 0 and len([c for c in year_categories.keys() if c != expected_category and year_categories[c] > 0]) > 0:
                category_analysis['mixing_detected'] = True
                category_analysis['mixing_details'].append({
                    'year': year,
                    'expected_count': expected_count,
                    'other_categories': {k: v for k, v in year_categories.items() if k != expected_category and v > 0}
                })
        
        # å…¨ä½“çµ±è¨ˆ
        category_analysis['total_questions_found'] = sum(
            year_data['expected_category_count'] 
            for year_data in category_analysis['year_analysis'].values()
        )
        
        category_analysis['all_categories_found'] = list(all_categories_found)
        
        # çµæœãƒ¬ãƒãƒ¼ãƒˆ
        print(f"\nğŸ“‹ {department_name}éƒ¨é–€ åˆ†æçµæœ:")
        print(f"  æœŸå¾…ã‚«ãƒ†ã‚´ãƒª: '{expected_category}'")
        print(f"  è©²å½“å•é¡Œç·æ•°: {category_analysis['total_questions_found']}å•")
        print(f"  ç™ºè¦‹ã•ã‚ŒãŸå…¨ã‚«ãƒ†ã‚´ãƒª: {category_analysis['all_categories_found']}")
        
        if category_analysis['mixing_detected']:
            print(f"  ğŸš¨ åˆ†é‡æ··åœ¨æ¤œå‡º: YES")
            for detail in category_analysis['mixing_details']:
                print(f"    å¹´åº¦{detail['year']}: æœŸå¾…ã‚«ãƒ†ã‚´ãƒª{detail['expected_count']}å•, ä»–ã‚«ãƒ†ã‚´ãƒª{detail['other_categories']}")
        else:
            print(f"  âœ… åˆ†é‡æ··åœ¨: ãªã—")
        
        return category_analysis
    
    # å…¨éƒ¨é–€åˆ†æå®Ÿè¡Œ
    comprehensive_results = {}
    
    for department in all_departments:
        try:
            analysis_result = analyze_category_consistency(department)
            comprehensive_results[department] = analysis_result
        except Exception as e:
            print(f"âŒ {department}éƒ¨é–€åˆ†æä¸­ã‚¨ãƒ©ãƒ¼: {e}")
            comprehensive_results[department] = {'error': str(e)}
    
    # å…¨ä½“ã‚µãƒãƒªãƒ¼
    print(f"\n{'='*100}")
    print("ğŸ¯ å…¨13éƒ¨é–€ åˆ†é‡æ··åœ¨å•é¡Œ æœ€çµ‚ã‚µãƒãƒªãƒ¼ï¼ˆçµ¶å¯¾ã«å˜˜ã‚’ã¤ã‹ãªã„ï¼‰")
    print('='*100)
    
    mixing_departments = []
    no_mixing_departments = []
    error_departments = []
    special_departments = []
    
    for dept, result in comprehensive_results.items():
        if 'error' in result:
            error_departments.append(dept)
            print(f"âŒ {dept}: {result['error']}")
        elif result.get('requires_separate_analysis'):
            special_departments.append(dept)
            print(f"âš ï¸ {dept}: åˆ¥é€”åˆ†æãŒå¿…è¦")
        elif result.get('mixing_detected'):
            mixing_departments.append(dept)
            print(f"ğŸš¨ {dept}: åˆ†é‡æ··åœ¨ã‚ã‚Š ({result['total_questions_found']}å•)")
        else:
            no_mixing_departments.append(dept)
            print(f"âœ… {dept}: åˆ†é‡æ··åœ¨ãªã— ({result['total_questions_found']}å•)")
    
    print(f"\nğŸ“Š åˆ†æçµæœçµ±è¨ˆ:")
    print(f"  åˆ†é‡æ··åœ¨æ¤œå‡ºéƒ¨é–€: {len(mixing_departments)}éƒ¨é–€ {mixing_departments}")
    print(f"  åˆ†é‡æ··åœ¨ãªã—éƒ¨é–€: {len(no_mixing_departments)}éƒ¨é–€ {no_mixing_departments}")
    print(f"  ç‰¹åˆ¥åˆ†æè¦éƒ¨é–€: {len(special_departments)}éƒ¨é–€ {special_departments}")
    print(f"  ã‚¨ãƒ©ãƒ¼éƒ¨é–€: {len(error_departments)}éƒ¨é–€ {error_departments}")
    
    # çµæœä¿å­˜
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    result_file = f"comprehensive_field_mixing_analysis_{timestamp}.json"
    
    try:
        with open(result_file, 'w', encoding='utf-8') as f:
            json.dump(comprehensive_results, f, ensure_ascii=False, indent=2)
        print(f"\nğŸ’¾ è©³ç´°çµæœä¿å­˜: {result_file}")
    except Exception as e:
        print(f"âŒ ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
    
    # é‡è¦ãªçµè«–
    print(f"\nğŸ¯ é‡è¦çµè«–ï¼ˆçµ¶å¯¾ã«å˜˜ã‚’ã¤ã‹ãªã„ï¼‰:")
    print(f"  è¾²æ¥­åœŸæœ¨ä»¥å¤–ã§ã‚‚åˆ†é‡æ··åœ¨ã®å¯èƒ½æ€§ãŒé«˜ã„ã“ã¨ãŒåˆ¤æ˜")
    print(f"  å…¨{len(all_departments)}éƒ¨é–€ä¸­ã€{len(mixing_departments)}éƒ¨é–€ã§æ··åœ¨æ¤œå‡º")
    print(f"  ã“ã‚Œã¯å…¨éƒ¨é–€ã«å½±éŸ¿ã™ã‚‹æ ¹æœ¬çš„ãªå•é¡Œ")
    
    return comprehensive_results

if __name__ == "__main__":
    result = comprehensive_field_mixing_analysis()